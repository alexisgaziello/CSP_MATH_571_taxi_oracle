{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from rfpimp import permutation_importances\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to get reproducible results\n",
    "\n",
    "# Seed value (can actually be different for each attribution step)\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    def dummie_and_drop(df, name):\n",
    "        # Creates a dummy variable, concatenates it and finally drops the original categorical variable.\n",
    "        # In order not to have redundant variables, one of the dummy variables is dropped too\n",
    "        dummies = pd.get_dummies(df[name]).rename(columns = lambda x: name + '_' + str(x))\n",
    "        dummies = dummies.drop(dummies.columns[-1], axis = 1)\n",
    "        df = pd.concat([df, dummies], axis = 1)\n",
    "        df.drop(columns = [name], inplace=True, axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def convert_to_categorical(df, categorical_variables, categories, need_pickup = True):\n",
    "        \"\"\" \n",
    "        The dataframe's selected variables are converted to categorical, and each variable's categories are also specified.\n",
    "        It is also specified if the \"pickup community area\" has to be converted into categorical or no. If it is not \n",
    "        converted into categorical it is because it's not going to be used in the model.            \n",
    "        \"\"\"\n",
    "        \n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            df.drop(columns = ['pickup_community_area'], inplace = True, axis = 1)\n",
    "            begin = 1\n",
    "        \n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def load(name, need_pickup = False, drop_correlated = False):\n",
    "    \n",
    "        # This parameter has to be set to True if the \"pickup_community_area\" variable is needed in the model\n",
    "        \n",
    "\n",
    "        # Load needed dataset and choose the useful columns\n",
    "        df = pd.read_csv(name) #'dataset_train.csv')\n",
    "\n",
    "        x = df[['pickup_community_area' ,'temperature', 'relative_humidity', 'wind_direction', 'wind_speed', 'precipitation_cat', \n",
    "                'sky_level', 'daytype', 'Day Name', 'Month', 'Hour', 'Fare Last Month', 'Trips Last Hour',\n",
    "                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)', 'Year']]\n",
    "#        float32=['temperature','relative_humidity','wind_direction','wind_speed','Fare Last Month', 'Trips Last Hour',\n",
    "#                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)']\n",
    "#        x= x[float32]=x[float32].astype('float32')\n",
    "        # Convert the categorical variables\n",
    "        categorical_variables = ['pickup_community_area', 'daytype', 'sky_level', 'Day Name', 'Month','Hour', 'Year']\n",
    "        categories = [[*(range(1,78))], ['U', 'W', 'A'], ['OVC', 'BKN', 'SCT', 'FEW', 'CLR', 'VV '], \n",
    "                      ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "                      [*(range(1,13))], [*(range(0, 24))], [2017, 2018, 2019]]\n",
    "\n",
    "        \n",
    "        \n",
    "        x = convert_to_categorical(x, categorical_variables, categories, need_pickup = need_pickup)\n",
    "\n",
    "        float32=['temperature','relative_humidity','wind_direction','wind_speed','Fare Last Month', 'Trips Last Hour',\n",
    "                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)']\n",
    "        \n",
    "        x[float32]=x[float32].astype('float32')\n",
    "        # Make dummy variables with the categorical ones\n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            begin = 1\n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            x = dummie_and_drop(x, name = categorical_variables[i])\n",
    "\n",
    "        y = df['Trips'].to_numpy()\n",
    "\n",
    "        if need_pickup == False:\n",
    "            # If we don't need the pickup, it means this is Neural Network case. Therefore we have to modify Y, in order\n",
    "            # to have \"n_areas\" outputs per input (because there are \"n_areas\" regressions per input)\n",
    "            n_areas = 77\n",
    "            y = np.reshape(y, [-1, n_areas]) # If \n",
    "        \n",
    "        if drop_correlated:\n",
    "            x.drop(columns = ['Trips Last Week (Same Hour)'], inplace = True, axis = 1)\n",
    "            x.drop(columns = ['Trips 2 Weeks Ago (Same Hour)'], inplace = True, axis = 1)\n",
    "\n",
    "#        x = x.to_numpy()\n",
    "        \n",
    "        return (x,y)   \n",
    "    \n",
    "# ------------------------------------- MAIN PROGRAM ------------------------\n",
    "\n",
    "    need_pickup = True \n",
    "    drop_correlated = False\n",
    "    \n",
    "    \n",
    "    name_train = 'dataset_train.csv'\n",
    "#    name_test = 'dataset_test.csv'\n",
    "    x, y = load(name_train, need_pickup, drop_correlated)\n",
    "#    x_test, y_test = load(name_test, need_pickup, drop_correlated)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15,shuffle=True)\n",
    "    \n",
    "    return (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iconsense\\Anaconda3\\envs\\abhishek\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1584937, 134)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No. of traning rows and col \n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traning the data using random forest regressor and getting standard hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestRegressor(n_estimators = 128,bootstrap=True,min_samples_leaf=8,oob_score=True,n_jobs=-1,max_features=0.5,verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 128\n",
      "building tree 2 of 128\n",
      "building tree 3 of 128\n",
      "building tree 4 of 128\n",
      "building tree 5 of 128\n",
      "building tree 6 of 128\n",
      "building tree 7 of 128\n",
      "building tree 8 of 128building tree 9 of 128\n",
      "building tree 10 of 128\n",
      "\n",
      "building tree 11 of 128\n",
      "building tree 12 of 128\n",
      "building tree 13 of 128\n",
      "building tree 14 of 128\n",
      "building tree 15 of 128\n",
      "building tree 16 of 128\n",
      "building tree 17 of 128\n",
      "building tree 18 of 128\n",
      "building tree 19 of 128building tree 20 of 128\n",
      "\n",
      "building tree 21 of 128\n",
      "building tree 22 of 128\n",
      "building tree 23 of 128\n",
      "building tree 24 of 128\n",
      "building tree 25 of 128\n",
      "building tree 26 of 128\n",
      "building tree 27 of 128\n",
      "building tree 28 of 128\n",
      "building tree 29 of 128\n",
      "building tree 30 of 128\n",
      "building tree 31 of 128\n",
      "building tree 32 of 128\n",
      "building tree 33 of 128\n",
      "building tree 34 of 128\n",
      "building tree 35 of 128\n",
      "building tree 36 of 128\n",
      "building tree 37 of 128\n",
      "building tree 38 of 128\n",
      "building tree 39 of 128\n",
      "building tree 40 of 128\n",
      "building tree 41 of 128\n",
      "building tree 42 of 128\n",
      "building tree 43 of 128\n",
      "building tree 44 of 128\n",
      "building tree 45 of 128\n",
      "building tree 46 of 128\n",
      "building tree 47 of 128\n",
      "building tree 48 of 128\n",
      "building tree 49 of 128\n",
      "building tree 50 of 128\n",
      "building tree 51 of 128\n",
      "building tree 52 of 128\n",
      "building tree 53 of 128\n",
      "building tree 54 of 128\n",
      "building tree 55 of 128\n",
      "building tree 56 of 128\n",
      "building tree 57 of 128\n",
      "building tree 58 of 128\n",
      "building tree 59 of 128\n",
      "building tree 60 of 128\n",
      "building tree 61 of 128\n",
      "building tree 62 of 128\n",
      "building tree 63 of 128\n",
      "building tree 64 of 128\n",
      "building tree 65 of 128\n",
      "building tree 66 of 128\n",
      "building tree 67 of 128\n",
      "building tree 68 of 128\n",
      "building tree 69 of 128\n",
      "building tree 70 of 128\n",
      "building tree 71 of 128\n",
      "building tree 72 of 128\n",
      "building tree 73 of 128\n",
      "building tree 74 of 128\n",
      "building tree 75 of 128\n",
      "building tree 76 of 128\n",
      "building tree 77 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  4.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 78 of 128\n",
      "building tree 79 of 128\n",
      "building tree 80 of 128\n",
      "building tree 81 of 128\n",
      "building tree 82 of 128\n",
      "building tree 83 of 128\n",
      "building tree 84 of 128\n",
      "building tree 85 of 128\n",
      "building tree 86 of 128\n",
      "building tree 87 of 128\n",
      "building tree 88 of 128\n",
      "building tree 89 of 128\n",
      "building tree 90 of 128\n",
      "building tree 91 of 128\n",
      "building tree 92 of 128\n",
      "building tree 93 of 128\n",
      "building tree 94 of 128\n",
      "building tree 95 of 128\n",
      "building tree 96 of 128\n",
      "building tree 97 of 128\n",
      "building tree 98 of 128\n",
      "building tree 99 of 128\n",
      "building tree 100 of 128\n",
      "building tree 101 of 128\n",
      "building tree 102 of 128\n",
      "building tree 103 of 128\n",
      "building tree 104 of 128\n",
      "building tree 105 of 128\n",
      "building tree 106 of 128\n",
      "building tree 107 of 128\n",
      "building tree 108 of 128\n",
      "building tree 109 of 128\n",
      "building tree 110 of 128\n",
      "building tree 111 of 128\n",
      "building tree 112 of 128\n",
      "building tree 113 of 128\n",
      "building tree 114 of 128\n",
      "building tree 115 of 128\n",
      "building tree 116 of 128\n",
      "building tree 117 of 128\n",
      "building tree 118 of 128\n",
      "building tree 119 of 128\n",
      "building tree 120 of 128\n",
      "building tree 121 of 128\n",
      "building tree 122 of 128\n",
      "building tree 123 of 128\n",
      "building tree 124 of 128\n",
      "building tree 125 of 128\n",
      "building tree 126 of 128\n",
      "building tree 127 of 128\n",
      "building tree 128 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 122 out of 128 | elapsed:  8.3min remaining:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done 128 out of 128 | elapsed:  8.4min finished\n"
     ]
    }
   ],
   "source": [
    "rf1=rf1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets): \n",
    "\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(rf):\n",
    "    \n",
    "    print(\"Traning Score\")\n",
    "    print(rf.score(x_train,y_train))\n",
    "    print(\"Test Score\")\n",
    "    print(rf.score(x_test,y_test))\n",
    "    print(\"MAE Train\")\n",
    "    train=np.rint(rf.predict(x_train))\n",
    "    test=np.rint(rf.predict(x_test))\n",
    "    print(mean_absolute_error(train, y_train))\n",
    "    print(\"MAE Test\")\n",
    "    print(mean_absolute_error(test, y_test))\n",
    "\n",
    "    print(\"MSE Train\")\n",
    "    print(mean_squared_error(train, y_train))\n",
    "    print(\"MSE Test\")\n",
    "    print(mean_squared_error(test, y_test))\n",
    "    print(\"RMSE Train\")\n",
    "    print(rmse(train,y_train))\n",
    "    print(\"RMSE Test\")\n",
    "    print(rmse(test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:  1.5min remaining:    4.2s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9728923616048942\n",
      "Test Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:   15.5s remaining:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:   15.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9575393705894802\n",
      "MAE Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:  1.4min remaining:    4.1s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:   15.2s remaining:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:   15.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756935449169273\n",
      "MAE Test\n",
      "0.9653265163839182\n",
      "MSE Train\n",
      "7.25883047717354\n",
      "MSE Test\n",
      "11.441259228802803\n",
      "RMSE Train\n",
      "2.69422168300486\n",
      "RMSE Test\n",
      "3.3824930493354755\n"
     ]
    }
   ],
   "source": [
    "metric(rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the Important features\n",
    "def feature_Imp(rf):\n",
    "    importances = rf1.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(x_train.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    \n",
    "    print(\"Top 10 Feature\")\n",
    "    print(x_train.columns[indices[:10]])\n",
    "    l=len(indices)\n",
    "    print(\"Least Important 10 Feature\")\n",
    "    print(x_train.columns[indices[(l-10):]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 6 (0.528896)\n",
      "2. feature 7 (0.265902)\n",
      "3. feature 8 (0.155177)\n",
      "4. feature 5 (0.018457)\n",
      "5. feature 16 (0.006476)\n",
      "6. feature 40 (0.003958)\n",
      "7. feature 1 (0.002112)\n",
      "8. feature 0 (0.001901)\n",
      "9. feature 116 (0.001743)\n",
      "10. feature 2 (0.001474)\n",
      "11. feature 36 (0.001401)\n",
      "12. feature 117 (0.001308)\n",
      "13. feature 3 (0.001251)\n",
      "14. feature 120 (0.000841)\n",
      "15. feature 86 (0.000738)\n",
      "16. feature 85 (0.000655)\n",
      "17. feature 132 (0.000526)\n",
      "18. feature 113 (0.000395)\n",
      "19. feature 114 (0.000392)\n",
      "20. feature 125 (0.000390)\n",
      "21. feature 129 (0.000388)\n",
      "22. feature 126 (0.000374)\n",
      "23. feature 84 (0.000341)\n",
      "24. feature 110 (0.000300)\n",
      "25. feature 97 (0.000292)\n",
      "26. feature 133 (0.000249)\n",
      "27. feature 90 (0.000249)\n",
      "28. feature 14 (0.000206)\n",
      "29. feature 128 (0.000199)\n",
      "30. feature 92 (0.000183)\n",
      "31. feature 115 (0.000165)\n",
      "32. feature 127 (0.000161)\n",
      "33. feature 131 (0.000158)\n",
      "34. feature 109 (0.000154)\n",
      "35. feature 41 (0.000132)\n",
      "36. feature 96 (0.000129)\n",
      "37. feature 100 (0.000125)\n",
      "38. feature 95 (0.000119)\n",
      "39. feature 130 (0.000110)\n",
      "40. feature 87 (0.000104)\n",
      "41. feature 15 (0.000100)\n",
      "42. feature 112 (0.000099)\n",
      "43. feature 88 (0.000098)\n",
      "44. feature 93 (0.000095)\n",
      "45. feature 124 (0.000093)\n",
      "46. feature 111 (0.000092)\n",
      "47. feature 89 (0.000090)\n",
      "48. feature 94 (0.000088)\n",
      "49. feature 119 (0.000084)\n",
      "50. feature 4 (0.000084)\n",
      "51. feature 104 (0.000078)\n",
      "52. feature 118 (0.000074)\n",
      "53. feature 108 (0.000065)\n",
      "54. feature 102 (0.000062)\n",
      "55. feature 101 (0.000060)\n",
      "56. feature 103 (0.000058)\n",
      "57. feature 99 (0.000057)\n",
      "58. feature 105 (0.000055)\n",
      "59. feature 107 (0.000054)\n",
      "60. feature 106 (0.000052)\n",
      "61. feature 98 (0.000047)\n",
      "62. feature 121 (0.000046)\n",
      "63. feature 91 (0.000041)\n",
      "64. feature 122 (0.000039)\n",
      "65. feature 123 (0.000031)\n",
      "66. feature 32 (0.000025)\n",
      "67. feature 11 (0.000022)\n",
      "68. feature 64 (0.000016)\n",
      "69. feature 12 (0.000010)\n",
      "70. feature 24 (0.000006)\n",
      "71. feature 30 (0.000006)\n",
      "72. feature 9 (0.000005)\n",
      "73. feature 10 (0.000005)\n",
      "74. feature 22 (0.000003)\n",
      "75. feature 29 (0.000003)\n",
      "76. feature 13 (0.000003)\n",
      "77. feature 19 (0.000003)\n",
      "78. feature 23 (0.000002)\n",
      "79. feature 49 (0.000002)\n",
      "80. feature 21 (0.000001)\n",
      "81. feature 43 (0.000001)\n",
      "82. feature 42 (0.000001)\n",
      "83. feature 31 (0.000001)\n",
      "84. feature 51 (0.000001)\n",
      "85. feature 67 (0.000001)\n",
      "86. feature 18 (0.000001)\n",
      "87. feature 27 (0.000001)\n",
      "88. feature 35 (0.000001)\n",
      "89. feature 33 (0.000001)\n",
      "90. feature 39 (0.000001)\n",
      "91. feature 37 (0.000001)\n",
      "92. feature 52 (0.000000)\n",
      "93. feature 20 (0.000000)\n",
      "94. feature 57 (0.000000)\n",
      "95. feature 46 (0.000000)\n",
      "96. feature 25 (0.000000)\n",
      "97. feature 47 (0.000000)\n",
      "98. feature 50 (0.000000)\n",
      "99. feature 28 (0.000000)\n",
      "100. feature 79 (0.000000)\n",
      "101. feature 77 (0.000000)\n",
      "102. feature 54 (0.000000)\n",
      "103. feature 61 (0.000000)\n",
      "104. feature 81 (0.000000)\n",
      "105. feature 17 (0.000000)\n",
      "106. feature 68 (0.000000)\n",
      "107. feature 76 (0.000000)\n",
      "108. feature 56 (0.000000)\n",
      "109. feature 44 (0.000000)\n",
      "110. feature 83 (0.000000)\n",
      "111. feature 74 (0.000000)\n",
      "112. feature 38 (0.000000)\n",
      "113. feature 78 (0.000000)\n",
      "114. feature 34 (0.000000)\n",
      "115. feature 48 (0.000000)\n",
      "116. feature 59 (0.000000)\n",
      "117. feature 69 (0.000000)\n",
      "118. feature 55 (0.000000)\n",
      "119. feature 75 (0.000000)\n",
      "120. feature 58 (0.000000)\n",
      "121. feature 53 (0.000000)\n",
      "122. feature 26 (0.000000)\n",
      "123. feature 66 (0.000000)\n",
      "124. feature 80 (0.000000)\n",
      "125. feature 45 (0.000000)\n",
      "126. feature 73 (0.000000)\n",
      "127. feature 62 (0.000000)\n",
      "128. feature 72 (0.000000)\n",
      "129. feature 60 (0.000000)\n",
      "130. feature 82 (0.000000)\n",
      "131. feature 65 (0.000000)\n",
      "132. feature 70 (0.000000)\n",
      "133. feature 71 (0.000000)\n",
      "134. feature 63 (0.000000)\n",
      "Top 10 Feature\n",
      "Index(['Trips Last Hour', 'Trips Last Week (Same Hour)',\n",
      "       'Trips 2 Weeks Ago (Same Hour)', 'Fare Last Month',\n",
      "       'pickup_community_area_8', 'pickup_community_area_32',\n",
      "       'relative_humidity', 'temperature', 'Hour_7', 'wind_direction'],\n",
      "      dtype='object')\n",
      "Least Important 10 Feature\n",
      "Index(['pickup_community_area_37', 'pickup_community_area_65',\n",
      "       'pickup_community_area_54', 'pickup_community_area_64',\n",
      "       'pickup_community_area_52', 'pickup_community_area_74',\n",
      "       'pickup_community_area_57', 'pickup_community_area_62',\n",
      "       'pickup_community_area_63', 'pickup_community_area_55'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_Imp(rf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traning the data after removing the correlated col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    def dummie_and_drop(df, name):\n",
    "        # Creates a dummy variable, concatenates it and finally drops the original categorical variable.\n",
    "        # In order not to have redundant variables, one of the dummy variables is dropped too\n",
    "        dummies = pd.get_dummies(df[name]).rename(columns = lambda x: name + '_' + str(x))\n",
    "        dummies = dummies.drop(dummies.columns[-1], axis = 1)\n",
    "        df = pd.concat([df, dummies], axis = 1)\n",
    "        df.drop(columns = [name], inplace=True, axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def convert_to_categorical(df, categorical_variables, categories, need_pickup = True):\n",
    "        \"\"\" \n",
    "        The dataframe's selected variables are converted to categorical, and each variable's categories are also specified.\n",
    "        It is also specified if the \"pickup community area\" has to be converted into categorical or no. If it is not \n",
    "        converted into categorical it is because it's not going to be used in the model.            \n",
    "        \"\"\"\n",
    "        \n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            df.drop(columns = ['pickup_community_area'], inplace = True, axis = 1)\n",
    "            begin = 1\n",
    "        \n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def load(name, need_pickup = False, drop_correlated = False):\n",
    "    \n",
    "        # This parameter has to be set to True if the \"pickup_community_area\" variable is needed in the model\n",
    "        \n",
    "\n",
    "        # Load needed dataset and choose the useful columns\n",
    "        df = pd.read_csv(name) #'dataset_train.csv')\n",
    "\n",
    "        x = df[['pickup_community_area' ,'temperature', 'relative_humidity', 'wind_direction', 'wind_speed', 'precipitation_cat', \n",
    "                'sky_level', 'daytype', 'Day Name', 'Month', 'Hour', 'Fare Last Month', 'Trips Last Hour',\n",
    "                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)', 'Year']]\n",
    "#        float32=['temperature','relative_humidity','wind_direction','wind_speed','Fare Last Month', 'Trips Last Hour',\n",
    "#                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)']\n",
    "#        x= x[float32]=x[float32].astype('float32')\n",
    "        # Convert the categorical variables\n",
    "        categorical_variables = ['pickup_community_area', 'daytype', 'sky_level', 'Day Name', 'Month','Hour', 'Year']\n",
    "        categories = [[*(range(1,78))], ['U', 'W', 'A'], ['OVC', 'BKN', 'SCT', 'FEW', 'CLR', 'VV '], \n",
    "                      ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "                      [*(range(1,13))], [*(range(0, 24))], [2017, 2018, 2019]]\n",
    "\n",
    "        \n",
    "        \n",
    "        x = convert_to_categorical(x, categorical_variables, categories, need_pickup = need_pickup)\n",
    "\n",
    "        float32=['temperature','relative_humidity','wind_direction','wind_speed','Fare Last Month', 'Trips Last Hour',\n",
    "                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)']\n",
    "        \n",
    "        x[float32]=x[float32].astype('float32')\n",
    "        # Make dummy variables with the categorical ones\n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            begin = 1\n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            x = dummie_and_drop(x, name = categorical_variables[i])\n",
    "\n",
    "        y = df['Trips'].to_numpy()\n",
    "\n",
    "        if need_pickup == False:\n",
    "            # If we don't need the pickup, it means this is Neural Network case. Therefore we have to modify Y, in order\n",
    "            # to have \"n_areas\" outputs per input (because there are \"n_areas\" regressions per input)\n",
    "            n_areas = 77\n",
    "            y = np.reshape(y, [-1, n_areas]) # If \n",
    "        \n",
    "        if drop_correlated:\n",
    "            x.drop(columns = ['Trips Last Week (Same Hour)'], inplace = True, axis = 1)\n",
    "            x.drop(columns = ['Trips 2 Weeks Ago (Same Hour)'], inplace = True, axis = 1)\n",
    "\n",
    "#        x = x.to_numpy()\n",
    "        \n",
    "        return (x,y)   \n",
    "    \n",
    "# ------------------------------------- MAIN PROGRAM ------------------------\n",
    "\n",
    "    need_pickup = True \n",
    "    drop_correlated = True\n",
    "    \n",
    "    \n",
    "    name_train = 'dataset_train.csv'\n",
    "#    name_test = 'dataset_test.csv'\n",
    "    x, y = load(name_train, need_pickup, drop_correlated)\n",
    "#    x_test, y_test = load(name_test, need_pickup, drop_correlated)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15,shuffle=True)\n",
    "    \n",
    "    return (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iconsense\\Anaconda3\\envs\\abhishek\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Iconsense\\Anaconda3\\envs\\abhishek\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the standard hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 128\n",
      "building tree 2 of 128\n",
      "building tree 3 of 128\n",
      "building tree 4 of 128\n",
      "building tree 5 of 128\n",
      "building tree 6 of 128\n",
      "building tree 7 of 128\n",
      "building tree 8 of 128\n",
      "building tree 9 of 128\n",
      "building tree 10 of 128\n",
      "building tree 11 of 128\n",
      "building tree 12 of 128\n",
      "building tree 13 of 128\n",
      "building tree 14 of 128\n",
      "building tree 15 of 128\n",
      "building tree 16 of 128\n",
      "building tree 17 of 128\n",
      "building tree 18 of 128\n",
      "building tree 19 of 128\n",
      "building tree 20 of 128\n",
      "building tree 21 of 128\n",
      "building tree 22 of 128\n",
      "building tree 23 of 128\n",
      "building tree 24 of 128\n",
      "building tree 25 of 128\n",
      "building tree 26 of 128\n",
      "building tree 27 of 128\n",
      "building tree 28 of 128\n",
      "building tree 29 of 128\n",
      "building tree 30 of 128\n",
      "building tree 31 of 128\n",
      "building tree 32 of 128\n",
      "building tree 33 of 128\n",
      "building tree 34 of 128\n",
      "building tree 35 of 128\n",
      "building tree 36 of 128\n",
      "building tree 37 of 128\n",
      "building tree 38 of 128\n",
      "building tree 39 of 128\n",
      "building tree 40 of 128\n",
      "building tree 41 of 128\n",
      "building tree 42 of 128\n",
      "building tree 43 of 128\n",
      "building tree 44 of 128\n",
      "building tree 45 of 128\n",
      "building tree 46 of 128\n",
      "building tree 47 of 128\n",
      "building tree 48 of 128\n",
      "building tree 49 of 128\n",
      "building tree 50 of 128\n",
      "building tree 51 of 128\n",
      "building tree 52 of 128\n",
      "building tree 53 of 128\n",
      "building tree 54 of 128\n",
      "building tree 55 of 128\n",
      "building tree 56 of 128\n",
      "building tree 57 of 128\n",
      "building tree 58 of 128\n",
      "building tree 59 of 128\n",
      "building tree 60 of 128\n",
      "building tree 61 of 128\n",
      "building tree 62 of 128\n",
      "building tree 63 of 128\n",
      "building tree 64 of 128\n",
      "building tree 65 of 128\n",
      "building tree 66 of 128\n",
      "building tree 67 of 128\n",
      "building tree 68 of 128\n",
      "building tree 69 of 128\n",
      "building tree 70 of 128\n",
      "building tree 71 of 128\n",
      "building tree 72 of 128\n",
      "building tree 73 of 128\n",
      "building tree 74 of 128\n",
      "building tree 75 of 128\n",
      "building tree 76 of 128\n",
      "building tree 77 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  4.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 78 of 128\n",
      "building tree 79 of 128\n",
      "building tree 80 of 128\n",
      "building tree 81 of 128\n",
      "building tree 82 of 128\n",
      "building tree 83 of 128\n",
      "building tree 84 of 128\n",
      "building tree 85 of 128\n",
      "building tree 86 of 128\n",
      "building tree 87 of 128\n",
      "building tree 88 of 128\n",
      "building tree 89 of 128\n",
      "building tree 90 of 128\n",
      "building tree 91 of 128\n",
      "building tree 92 of 128\n",
      "building tree 93 of 128\n",
      "building tree 94 of 128\n",
      "building tree 95 of 128\n",
      "building tree 96 of 128\n",
      "building tree 97 of 128\n",
      "building tree 98 of 128\n",
      "building tree 99 of 128\n",
      "building tree 100 of 128\n",
      "building tree 101 of 128\n",
      "building tree 102 of 128\n",
      "building tree 103 of 128\n",
      "building tree 104 of 128\n",
      "building tree 105 of 128\n",
      "building tree 106 of 128\n",
      "building tree 107 of 128\n",
      "building tree 108 of 128\n",
      "building tree 109 of 128\n",
      "building tree 110 of 128\n",
      "building tree 111 of 128\n",
      "building tree 112 of 128\n",
      "building tree 113 of 128\n",
      "building tree 114 of 128\n",
      "building tree 115 of 128\n",
      "building tree 116 of 128\n",
      "building tree 117 of 128\n",
      "building tree 118 of 128\n",
      "building tree 119 of 128\n",
      "building tree 120 of 128\n",
      "building tree 121 of 128\n",
      "building tree 122 of 128\n",
      "building tree 123 of 128\n",
      "building tree 124 of 128\n",
      "building tree 125 of 128\n",
      "building tree 126 of 128\n",
      "building tree 127 of 128\n",
      "building tree 128 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 122 out of 128 | elapsed:  8.7min remaining:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 128 out of 128 | elapsed:  8.9min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:  1.5min remaining:    4.4s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9726030551218093"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestRegressor(n_estimators = 128,bootstrap=True,min_samples_leaf=8,oob_score=True,n_jobs=-1,max_features=0.5,verbose=4)\n",
    "\n",
    "rf2=rf2.fit(x_train, y_train)\n",
    "\n",
    "rf2.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:  1.5min remaining:    4.4s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9726030551218093\n",
      "Test Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:   16.0s remaining:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:   16.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9582400738887416\n",
      "MAE Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:  1.5min remaining:    4.4s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:   16.0s remaining:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:   16.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7648682565931643\n",
      "MAE Test\n",
      "0.9419725057652085\n",
      "MSE Train\n",
      "7.365646710247789\n",
      "MSE Test\n",
      "10.999520906701942\n",
      "RMSE Train\n",
      "2.7139724962216896\n",
      "RMSE Test\n",
      "3.316552563536713\n"
     ]
    }
   ],
   "source": [
    "metric(rf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can clearly see that the metric got worse after dropping the correlated\n",
    "## Therefore we will not drop them in future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    def dummie_and_drop(df, name):\n",
    "        # Creates a dummy variable, concatenates it and finally drops the original categorical variable.\n",
    "        # In order not to have redundant variables, one of the dummy variables is dropped too\n",
    "        dummies = pd.get_dummies(df[name]).rename(columns = lambda x: name + '_' + str(x))\n",
    "        dummies = dummies.drop(dummies.columns[-1], axis = 1)\n",
    "        df = pd.concat([df, dummies], axis = 1)\n",
    "        df.drop(columns = [name], inplace=True, axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def convert_to_categorical(df, categorical_variables, categories, need_pickup = True):\n",
    "        \"\"\" \n",
    "        The dataframe's selected variables are converted to categorical, and each variable's categories are also specified.\n",
    "        It is also specified if the \"pickup community area\" has to be converted into categorical or no. If it is not \n",
    "        converted into categorical it is because it's not going to be used in the model.            \n",
    "        \"\"\"\n",
    "        \n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            df.drop(columns = ['pickup_community_area'], inplace = True, axis = 1)\n",
    "            begin = 1\n",
    "        \n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def load(name, need_pickup = False, drop_correlated = False):\n",
    "    \n",
    "        # This parameter has to be set to True if the \"pickup_community_area\" variable is needed in the model\n",
    "        \n",
    "\n",
    "        # Load needed dataset and choose the useful columns\n",
    "        df = pd.read_csv(name) #'dataset_train.csv')\n",
    "\n",
    "        x = df[['pickup_community_area' ,'temperature', 'relative_humidity', 'wind_direction', 'wind_speed', 'precipitation_cat', \n",
    "                'sky_level', 'daytype', 'Day Name', 'Month', 'Hour', 'Fare Last Month', 'Trips Last Hour',\n",
    "                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)', 'Year']]\n",
    "#        float32=['temperature','relative_humidity','wind_direction','wind_speed','Fare Last Month', 'Trips Last Hour',\n",
    "#                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)']\n",
    "#        x= x[float32]=x[float32].astype('float32')\n",
    "        # Convert the categorical variables\n",
    "        categorical_variables = ['pickup_community_area', 'daytype', 'sky_level', 'Day Name', 'Month','Hour', 'Year']\n",
    "        categories = [[*(range(1,78))], ['U', 'W', 'A'], ['OVC', 'BKN', 'SCT', 'FEW', 'CLR', 'VV '], \n",
    "                      ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "                      [*(range(1,13))], [*(range(0, 24))], [2017, 2018, 2019]]\n",
    "\n",
    "        \n",
    "        \n",
    "        x = convert_to_categorical(x, categorical_variables, categories, need_pickup = need_pickup)\n",
    "\n",
    "        float32=['temperature','relative_humidity','wind_direction','wind_speed','Fare Last Month', 'Trips Last Hour',\n",
    "                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)']\n",
    "        \n",
    "        x[float32]=x[float32].astype('float32')\n",
    "        # Make dummy variables with the categorical ones\n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            begin = 1\n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            x = dummie_and_drop(x, name = categorical_variables[i])\n",
    "\n",
    "        y = df['Trips'].to_numpy()\n",
    "\n",
    "        if need_pickup == False:\n",
    "            # If we don't need the pickup, it means this is Neural Network case. Therefore we have to modify Y, in order\n",
    "            # to have \"n_areas\" outputs per input (because there are \"n_areas\" regressions per input)\n",
    "            n_areas = 77\n",
    "            y = np.reshape(y, [-1, n_areas]) # If \n",
    "        \n",
    "        if drop_correlated:\n",
    "            x.drop(columns = ['Trips Last Week (Same Hour)'], inplace = True, axis = 1)\n",
    "            x.drop(columns = ['Trips 2 Weeks Ago (Same Hour)'], inplace = True, axis = 1)\n",
    "\n",
    "#        x = x.to_numpy()\n",
    "        \n",
    "        return (x,y)   \n",
    "    \n",
    "# ------------------------------------- MAIN PROGRAM ------------------------\n",
    "\n",
    "    need_pickup = True \n",
    "    drop_correlated = False\n",
    "    \n",
    "    \n",
    "    name_train = 'dataset_train.csv'\n",
    "#    name_test = 'dataset_test.csv'\n",
    "    x, y = load(name_train, need_pickup, drop_correlated)\n",
    "#    x_test, y_test = load(name_test, need_pickup, drop_correlated)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15,shuffle=True)\n",
    "    \n",
    "    return (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iconsense\\Anaconda3\\envs\\abhishek\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Iconsense\\Anaconda3\\envs\\abhishek\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test=load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting diffrent hyper-parameters to get the best metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 256\n",
      "building tree 2 of 256\n",
      "building tree 3 of 256\n",
      "building tree 4 of 256building tree 5 of 256\n",
      "building tree 6 of 256\n",
      "\n",
      "building tree 7 of 256\n",
      "building tree 8 of 256\n",
      "building tree 9 of 256building tree 10 of 256building tree 11 of 256\n",
      "building tree 12 of 256\n",
      "\n",
      "building tree 13 of 256\n",
      "\n",
      "building tree 14 of 256\n",
      "building tree 15 of 256\n",
      "building tree 16 of 256\n",
      "building tree 17 of 256\n",
      "building tree 18 of 256building tree 19 of 256\n",
      "building tree 20 of 256\n",
      "\n",
      "building tree 21 of 256\n",
      "building tree 22 of 256\n",
      "building tree 23 of 256\n",
      "building tree 24 of 256\n",
      "building tree 25 of 256\n",
      "building tree 26 of 256\n",
      "building tree 27 of 256\n",
      "building tree 28 of 256\n",
      "building tree 29 of 256\n",
      "building tree 30 of 256\n",
      "building tree 31 of 256\n",
      "building tree 32 of 256\n",
      "building tree 33 of 256\n",
      "building tree 34 of 256\n",
      "building tree 35 of 256\n",
      "building tree 36 of 256\n",
      "building tree 37 of 256\n",
      "building tree 38 of 256\n",
      "building tree 39 of 256\n",
      "building tree 40 of 256\n",
      "building tree 41 of 256\n",
      "building tree 42 of 256\n",
      "building tree 43 of 256\n",
      "building tree 44 of 256\n",
      "building tree 45 of 256\n",
      "building tree 46 of 256\n",
      "building tree 47 of 256\n",
      "building tree 48 of 256\n",
      "building tree 49 of 256\n",
      "building tree 50 of 256\n",
      "building tree 51 of 256\n",
      "building tree 52 of 256\n",
      "building tree 53 of 256\n",
      "building tree 54 of 256\n",
      "building tree 55 of 256\n",
      "building tree 56 of 256\n",
      "building tree 57 of 256\n",
      "building tree 58 of 256\n",
      "building tree 59 of 256\n",
      "building tree 60 of 256\n",
      "building tree 61 of 256\n",
      "building tree 62 of 256\n",
      "building tree 63 of 256\n",
      "building tree 64 of 256\n",
      "building tree 65 of 256\n",
      "building tree 66 of 256\n",
      "building tree 67 of 256\n",
      "building tree 68 of 256\n",
      "building tree 69 of 256\n",
      "building tree 70 of 256\n",
      "building tree 71 of 256\n",
      "building tree 72 of 256\n",
      "building tree 73 of 256\n",
      "building tree 74 of 256\n",
      "building tree 75 of 256\n",
      "building tree 76 of 256\n",
      "building tree 77 of 256\n",
      "building tree 78 of 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 79 of 256\n",
      "building tree 80 of 256\n",
      "building tree 81 of 256\n",
      "building tree 82 of 256\n",
      "building tree 83 of 256\n",
      "building tree 84 of 256\n",
      "building tree 85 of 256\n",
      "building tree 86 of 256\n",
      "building tree 87 of 256\n",
      "building tree 88 of 256\n",
      "building tree 89 of 256\n",
      "building tree 90 of 256\n",
      "building tree 91 of 256\n",
      "building tree 92 of 256\n",
      "building tree 93 of 256\n",
      "building tree 94 of 256\n",
      "building tree 95 of 256\n",
      "building tree 96 of 256\n",
      "building tree 97 of 256\n",
      "building tree 98 of 256\n",
      "building tree 99 of 256\n",
      "building tree 100 of 256\n",
      "building tree 101 of 256\n",
      "building tree 102 of 256\n",
      "building tree 103 of 256\n",
      "building tree 104 of 256\n",
      "building tree 105 of 256\n",
      "building tree 106 of 256\n",
      "building tree 107 of 256\n",
      "building tree 108 of 256\n",
      "building tree 109 of 256\n",
      "building tree 110 of 256\n",
      "building tree 111 of 256\n",
      "building tree 112 of 256\n",
      "building tree 113 of 256\n",
      "building tree 114 of 256\n",
      "building tree 115 of 256\n",
      "building tree 116 of 256\n",
      "building tree 117 of 256\n",
      "building tree 118 of 256\n",
      "building tree 119 of 256\n",
      "building tree 120 of 256\n",
      "building tree 121 of 256\n",
      "building tree 122 of 256\n",
      "building tree 123 of 256\n",
      "building tree 124 of 256\n",
      "building tree 125 of 256\n",
      "building tree 126 of 256\n",
      "building tree 127 of 256\n",
      "building tree 128 of 256\n",
      "building tree 129 of 256\n",
      "building tree 130 of 256\n",
      "building tree 131 of 256\n",
      "building tree 132 of 256\n",
      "building tree 133 of 256\n",
      "building tree 134 of 256building tree 135 of 256\n",
      "\n",
      "building tree 136 of 256\n",
      "building tree 137 of 256\n",
      "building tree 138 of 256\n",
      "building tree 139 of 256\n",
      "building tree 140 of 256\n",
      "building tree 141 of 256\n",
      "building tree 142 of 256\n",
      "building tree 143 of 256\n",
      "building tree 144 of 256\n",
      "building tree 145 of 256\n",
      "building tree 146 of 256\n",
      "building tree 147 of 256\n",
      "building tree 148 of 256\n",
      "building tree 149 of 256\n",
      "building tree 150 of 256\n",
      "building tree 151 of 256\n",
      "building tree 152 of 256\n",
      "building tree 153 of 256\n",
      "building tree 154 of 256\n",
      "building tree 155 of 256\n",
      "building tree 156 of 256\n",
      "building tree 157 of 256\n",
      "building tree 158 of 256\n",
      "building tree 159 of 256\n",
      "building tree 160 of 256\n",
      "building tree 161 of 256\n",
      "building tree 162 of 256\n",
      "building tree 163 of 256\n",
      "building tree 164 of 256\n",
      "building tree 165 of 256\n",
      "building tree 166 of 256\n",
      "building tree 167 of 256\n",
      "building tree 168 of 256\n",
      "building tree 169 of 256\n",
      "building tree 170 of 256\n",
      "building tree 171 of 256\n",
      "building tree 172 of 256\n",
      "building tree 173 of 256\n",
      "building tree 174 of 256\n",
      "building tree 175 of 256\n",
      "building tree 176 of 256\n",
      "building tree 177 of 256\n",
      "building tree 178 of 256\n",
      "building tree 179 of 256\n",
      "building tree 180 of 256\n",
      "building tree 181 of 256\n",
      "building tree 182 of 256\n",
      "building tree 183 of 256\n",
      "building tree 184 of 256\n",
      "building tree 185 of 256\n",
      "building tree 186 of 256\n",
      "building tree 187 of 256\n",
      "building tree 188 of 256\n",
      "building tree 189 of 256\n",
      "building tree 190 of 256\n",
      "building tree 191 of 256\n",
      "building tree 192 of 256\n",
      "building tree 193 of 256\n",
      "building tree 194 of 256\n",
      "building tree 195 of 256\n",
      "building tree 196 of 256\n",
      "building tree 197 of 256\n",
      "building tree 198 of 256\n",
      "building tree 199 of 256\n",
      "building tree 200 of 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:  4.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 201 of 256\n",
      "building tree 202 of 256\n",
      "building tree 203 of 256\n",
      "building tree 204 of 256\n",
      "building tree 205 of 256\n",
      "building tree 206 of 256\n",
      "building tree 207 of 256\n",
      "building tree 208 of 256\n",
      "building tree 209 of 256\n",
      "building tree 210 of 256\n",
      "building tree 211 of 256\n",
      "building tree 212 of 256\n",
      "building tree 213 of 256\n",
      "building tree 214 of 256\n",
      "building tree 215 of 256\n",
      "building tree 216 of 256\n",
      "building tree 217 of 256\n",
      "building tree 218 of 256\n",
      "building tree 219 of 256\n",
      "building tree 220 of 256\n",
      "building tree 221 of 256\n",
      "building tree 222 of 256\n",
      "building tree 223 of 256\n",
      "building tree 224 of 256\n",
      "building tree 225 of 256\n",
      "building tree 226 of 256\n",
      "building tree 227 of 256\n",
      "building tree 228 of 256\n",
      "building tree 229 of 256\n",
      "building tree 230 of 256\n",
      "building tree 231 of 256\n",
      "building tree 232 of 256\n",
      "building tree 233 of 256\n",
      "building tree 234 of 256\n",
      "building tree 235 of 256\n",
      "building tree 236 of 256\n",
      "building tree 237 of 256\n",
      "building tree 238 of 256\n",
      "building tree 239 of 256\n",
      "building tree 240 of 256\n",
      "building tree 241 of 256\n",
      "building tree 242 of 256\n",
      "building tree 243 of 256\n",
      "building tree 244 of 256\n",
      "building tree 245 of 256\n",
      "building tree 246 of 256\n",
      "building tree 247 of 256\n",
      "building tree 248 of 256\n",
      "building tree 249 of 256\n",
      "building tree 250 of 256\n",
      "building tree 251 of 256\n",
      "building tree 252 of 256\n",
      "building tree 253 of 256\n",
      "building tree 254 of 256\n",
      "building tree 255 of 256\n",
      "building tree 256 of 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 256 out of 256 | elapsed:  5.5min finished\n"
     ]
    }
   ],
   "source": [
    "rf3 = RandomForestRegressor(n_estimators = 256,bootstrap=True,min_samples_leaf=64,oob_score=True,n_jobs=-1,\n",
    "                           max_features='sqrt',verbose=4,min_samples_split=64 )\n",
    "\n",
    "rf3=rf3.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=20)]: Done 181 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=20)]: Done 256 out of 256 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9386046293730707\n",
      "Test Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=20)]: Done 181 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=20)]: Done 256 out of 256 | elapsed:   24.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.937499777107107\n",
      "MAE Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=20)]: Done 181 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=20)]: Done 256 out of 256 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=20)]: Done 181 tasks      | elapsed:   17.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0629368864503763\n",
      "MAE Test\n",
      "1.0656965623268202\n",
      "MSE Train\n",
      "16.46358435698075\n",
      "MSE Test\n",
      "16.405455943080856\n",
      "RMSE Train\n",
      "4.0575342705861095\n",
      "RMSE Test\n",
      "4.050364914804696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 256 out of 256 | elapsed:   24.3s finished\n"
     ]
    }
   ],
   "source": [
    "metric(rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 256building tree 2 of 256\n",
      "building tree 3 of 256\n",
      "building tree 4 of 256\n",
      "building tree 5 of 256\n",
      "building tree 6 of 256\n",
      "building tree 7 of 256building tree 8 of 256\n",
      "\n",
      "\n",
      "building tree 9 of 256\n",
      "building tree 10 of 256\n",
      "building tree 11 of 256\n",
      "building tree 12 of 256\n",
      "building tree 13 of 256\n",
      "building tree 14 of 256building tree 15 of 256\n",
      "\n",
      "building tree 16 of 256\n",
      "building tree 17 of 256building tree 18 of 256\n",
      "building tree 19 of 256\n",
      "building tree 20 of 256\n",
      "\n",
      "building tree 21 of 256\n",
      "building tree 22 of 256\n",
      "building tree 23 of 256\n",
      "building tree 24 of 256\n",
      "building tree 25 of 256\n",
      "building tree 26 of 256\n",
      "building tree 27 of 256\n",
      "building tree 28 of 256\n",
      "building tree 29 of 256\n",
      "building tree 30 of 256\n",
      "building tree 31 of 256\n",
      "building tree 32 of 256\n",
      "building tree 33 of 256\n",
      "building tree 34 of 256\n",
      "building tree 35 of 256\n",
      "building tree 36 of 256\n",
      "building tree 37 of 256\n",
      "building tree 38 of 256\n",
      "building tree 39 of 256\n",
      "building tree 40 of 256\n",
      "building tree 41 of 256\n",
      "building tree 42 of 256\n",
      "building tree 43 of 256\n",
      "building tree 44 of 256\n",
      "building tree 45 of 256\n",
      "building tree 46 of 256\n",
      "building tree 47 of 256\n",
      "building tree 48 of 256\n",
      "building tree 49 of 256\n",
      "building tree 50 of 256\n",
      "building tree 51 of 256\n",
      "building tree 52 of 256\n",
      "building tree 53 of 256\n",
      "building tree 54 of 256\n",
      "building tree 55 of 256\n",
      "building tree 56 of 256\n",
      "building tree 57 of 256\n",
      "building tree 58 of 256\n",
      "building tree 59 of 256\n",
      "building tree 60 of 256\n",
      "building tree 61 of 256\n",
      "building tree 62 of 256\n",
      "building tree 63 of 256\n",
      "building tree 64 of 256\n",
      "building tree 65 of 256\n",
      "building tree 66 of 256\n",
      "building tree 67 of 256\n",
      "building tree 68 of 256\n",
      "building tree 69 of 256\n",
      "building tree 70 of 256\n",
      "building tree 71 of 256\n",
      "building tree 72 of 256\n",
      "building tree 73 of 256\n",
      "building tree 74 of 256\n",
      "building tree 75 of 256\n",
      "building tree 76 of 256\n",
      "building tree 77 of 256\n",
      "building tree 78 of 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  3.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 79 of 256\n",
      "building tree 80 of 256\n",
      "building tree 81 of 256\n",
      "building tree 82 of 256\n",
      "building tree 83 of 256\n",
      "building tree 84 of 256\n",
      "building tree 85 of 256\n",
      "building tree 86 of 256\n",
      "building tree 87 of 256\n",
      "building tree 88 of 256\n",
      "building tree 89 of 256\n",
      "building tree 90 of 256\n",
      "building tree 91 of 256\n",
      "building tree 92 of 256\n",
      "building tree 93 of 256\n",
      "building tree 94 of 256\n",
      "building tree 95 of 256\n",
      "building tree 96 of 256\n",
      "building tree 97 of 256\n",
      "building tree 98 of 256\n",
      "building tree 99 of 256\n",
      "building tree 100 of 256\n",
      "building tree 101 of 256\n",
      "building tree 102 of 256\n",
      "building tree 103 of 256\n",
      "building tree 104 of 256\n",
      "building tree 105 of 256\n",
      "building tree 106 of 256\n",
      "building tree 107 of 256\n",
      "building tree 108 of 256\n",
      "building tree 109 of 256\n",
      "building tree 110 of 256\n",
      "building tree 111 of 256\n",
      "building tree 112 of 256\n",
      "building tree 113 of 256\n",
      "building tree 114 of 256\n",
      "building tree 115 of 256\n",
      "building tree 116 of 256\n",
      "building tree 117 of 256\n",
      "building tree 118 of 256\n",
      "building tree 119 of 256\n",
      "building tree 120 of 256\n",
      "building tree 121 of 256\n",
      "building tree 122 of 256\n",
      "building tree 123 of 256\n",
      "building tree 124 of 256\n",
      "building tree 125 of 256\n",
      "building tree 126 of 256\n",
      "building tree 127 of 256\n",
      "building tree 128 of 256\n",
      "building tree 129 of 256\n",
      "building tree 130 of 256\n",
      "building tree 131 of 256\n",
      "building tree 132 of 256\n",
      "building tree 133 of 256\n",
      "building tree 134 of 256\n",
      "building tree 135 of 256\n",
      "building tree 136 of 256\n",
      "building tree 137 of 256\n",
      "building tree 138 of 256\n",
      "building tree 139 of 256\n",
      "building tree 140 of 256\n",
      "building tree 141 of 256\n",
      "building tree 142 of 256\n",
      "building tree 143 of 256\n",
      "building tree 144 of 256\n",
      "building tree 145 of 256\n",
      "building tree 146 of 256\n",
      "building tree 147 of 256\n",
      "building tree 148 of 256\n",
      "building tree 149 of 256\n",
      "building tree 150 of 256\n",
      "building tree 151 of 256\n",
      "building tree 152 of 256\n",
      "building tree 153 of 256\n",
      "building tree 154 of 256\n",
      "building tree 155 of 256\n",
      "building tree 156 of 256\n",
      "building tree 157 of 256\n",
      "building tree 158 of 256\n",
      "building tree 159 of 256\n",
      "building tree 160 of 256\n",
      "building tree 161 of 256\n",
      "building tree 162 of 256\n",
      "building tree 163 of 256\n",
      "building tree 164 of 256\n",
      "building tree 165 of 256\n",
      "building tree 166 of 256\n",
      "building tree 167 of 256\n",
      "building tree 168 of 256\n",
      "building tree 169 of 256\n",
      "building tree 170 of 256\n",
      "building tree 171 of 256\n",
      "building tree 172 of 256\n",
      "building tree 173 of 256\n",
      "building tree 174 of 256\n",
      "building tree 175 of 256\n",
      "building tree 176 of 256\n",
      "building tree 177 of 256\n",
      "building tree 178 of 256\n",
      "building tree 179 of 256\n",
      "building tree 180 of 256\n",
      "building tree 181 of 256\n",
      "building tree 182 of 256\n",
      "building tree 183 of 256\n",
      "building tree 184 of 256\n",
      "building tree 185 of 256\n",
      "building tree 186 of 256\n",
      "building tree 187 of 256\n",
      "building tree 188 of 256\n",
      "building tree 189 of 256\n",
      "building tree 190 of 256\n",
      "building tree 191 of 256\n",
      "building tree 192 of 256\n",
      "building tree 193 of 256\n",
      "building tree 194 of 256\n",
      "building tree 195 of 256\n",
      "building tree 196 of 256\n",
      "building tree 197 of 256\n",
      "building tree 198 of 256\n",
      "building tree 199 of 256\n",
      "building tree 200 of 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:  9.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 201 of 256\n",
      "building tree 202 of 256\n",
      "building tree 203 of 256\n",
      "building tree 204 of 256\n",
      "building tree 205 of 256\n",
      "building tree 206 of 256\n",
      "building tree 207 of 256\n",
      "building tree 208 of 256\n",
      "building tree 209 of 256\n",
      "building tree 210 of 256\n",
      "building tree 211 of 256\n",
      "building tree 212 of 256\n",
      "building tree 213 of 256\n",
      "building tree 214 of 256\n",
      "building tree 215 of 256\n",
      "building tree 216 of 256\n",
      "building tree 217 of 256\n",
      "building tree 218 of 256\n",
      "building tree 219 of 256\n",
      "building tree 220 of 256\n",
      "building tree 221 of 256\n",
      "building tree 222 of 256\n",
      "building tree 223 of 256\n",
      "building tree 224 of 256\n",
      "building tree 225 of 256\n",
      "building tree 226 of 256\n",
      "building tree 227 of 256\n",
      "building tree 228 of 256\n",
      "building tree 229 of 256\n",
      "building tree 230 of 256\n",
      "building tree 231 of 256\n",
      "building tree 232 of 256\n",
      "building tree 233 of 256\n",
      "building tree 234 of 256\n",
      "building tree 235 of 256\n",
      "building tree 236 of 256\n",
      "building tree 237 of 256\n",
      "building tree 238 of 256\n",
      "building tree 239 of 256\n",
      "building tree 240 of 256\n",
      "building tree 241 of 256\n",
      "building tree 242 of 256\n",
      "building tree 243 of 256\n",
      "building tree 244 of 256\n",
      "building tree 245 of 256\n",
      "building tree 246 of 256\n",
      "building tree 247 of 256\n",
      "building tree 248 of 256\n",
      "building tree 249 of 256\n",
      "building tree 250 of 256\n",
      "building tree 251 of 256\n",
      "building tree 252 of 256\n",
      "building tree 253 of 256\n",
      "building tree 254 of 256\n",
      "building tree 255 of 256\n",
      "building tree 256 of 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 256 out of 256 | elapsed: 12.7min finished\n"
     ]
    }
   ],
   "source": [
    "rf4 = RandomForestRegressor(n_estimators = 256,bootstrap=True,min_samples_leaf=64,oob_score=True,n_jobs=-1,\n",
    "                           max_features=0.4,verbose=4,min_samples_split=64 )\n",
    "rf4=rf4.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best metric in the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=20)]: Done 181 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=20)]: Done 256 out of 256 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9536129966789673\n",
      "Test Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=20)]: Done 181 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=20)]: Done 256 out of 256 | elapsed:   20.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9516296617820463\n",
      "MAE Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=20)]: Done 181 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=20)]: Done 256 out of 256 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=20)]: Done 181 tasks      | elapsed:   14.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979572058700125\n",
      "MAE Test\n",
      "0.9962280341085825\n",
      "MSE Train\n",
      "12.453671029195482\n",
      "MSE Test\n",
      "12.706984393714581\n",
      "RMSE Train\n",
      "3.528975917910957\n",
      "RMSE Test\n",
      "3.5646857356174584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 256 out of 256 | elapsed:   20.4s finished\n"
     ]
    }
   ],
   "source": [
    "metric(rf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 6 (0.528896)\n",
      "2. feature 7 (0.265902)\n",
      "3. feature 8 (0.155177)\n",
      "4. feature 5 (0.018457)\n",
      "5. feature 16 (0.006476)\n",
      "6. feature 40 (0.003958)\n",
      "7. feature 1 (0.002112)\n",
      "8. feature 0 (0.001901)\n",
      "9. feature 116 (0.001743)\n",
      "10. feature 2 (0.001474)\n",
      "11. feature 36 (0.001401)\n",
      "12. feature 117 (0.001308)\n",
      "13. feature 3 (0.001251)\n",
      "14. feature 120 (0.000841)\n",
      "15. feature 86 (0.000738)\n",
      "16. feature 85 (0.000655)\n",
      "17. feature 132 (0.000526)\n",
      "18. feature 113 (0.000395)\n",
      "19. feature 114 (0.000392)\n",
      "20. feature 125 (0.000390)\n",
      "21. feature 129 (0.000388)\n",
      "22. feature 126 (0.000374)\n",
      "23. feature 84 (0.000341)\n",
      "24. feature 110 (0.000300)\n",
      "25. feature 97 (0.000292)\n",
      "26. feature 133 (0.000249)\n",
      "27. feature 90 (0.000249)\n",
      "28. feature 14 (0.000206)\n",
      "29. feature 128 (0.000199)\n",
      "30. feature 92 (0.000183)\n",
      "31. feature 115 (0.000165)\n",
      "32. feature 127 (0.000161)\n",
      "33. feature 131 (0.000158)\n",
      "34. feature 109 (0.000154)\n",
      "35. feature 41 (0.000132)\n",
      "36. feature 96 (0.000129)\n",
      "37. feature 100 (0.000125)\n",
      "38. feature 95 (0.000119)\n",
      "39. feature 130 (0.000110)\n",
      "40. feature 87 (0.000104)\n",
      "41. feature 15 (0.000100)\n",
      "42. feature 112 (0.000099)\n",
      "43. feature 88 (0.000098)\n",
      "44. feature 93 (0.000095)\n",
      "45. feature 124 (0.000093)\n",
      "46. feature 111 (0.000092)\n",
      "47. feature 89 (0.000090)\n",
      "48. feature 94 (0.000088)\n",
      "49. feature 119 (0.000084)\n",
      "50. feature 4 (0.000084)\n",
      "51. feature 104 (0.000078)\n",
      "52. feature 118 (0.000074)\n",
      "53. feature 108 (0.000065)\n",
      "54. feature 102 (0.000062)\n",
      "55. feature 101 (0.000060)\n",
      "56. feature 103 (0.000058)\n",
      "57. feature 99 (0.000057)\n",
      "58. feature 105 (0.000055)\n",
      "59. feature 107 (0.000054)\n",
      "60. feature 106 (0.000052)\n",
      "61. feature 98 (0.000047)\n",
      "62. feature 121 (0.000046)\n",
      "63. feature 91 (0.000041)\n",
      "64. feature 122 (0.000039)\n",
      "65. feature 123 (0.000031)\n",
      "66. feature 32 (0.000025)\n",
      "67. feature 11 (0.000022)\n",
      "68. feature 64 (0.000016)\n",
      "69. feature 12 (0.000010)\n",
      "70. feature 24 (0.000006)\n",
      "71. feature 30 (0.000006)\n",
      "72. feature 9 (0.000005)\n",
      "73. feature 10 (0.000005)\n",
      "74. feature 22 (0.000003)\n",
      "75. feature 29 (0.000003)\n",
      "76. feature 13 (0.000003)\n",
      "77. feature 19 (0.000003)\n",
      "78. feature 23 (0.000002)\n",
      "79. feature 49 (0.000002)\n",
      "80. feature 21 (0.000001)\n",
      "81. feature 43 (0.000001)\n",
      "82. feature 42 (0.000001)\n",
      "83. feature 31 (0.000001)\n",
      "84. feature 51 (0.000001)\n",
      "85. feature 67 (0.000001)\n",
      "86. feature 18 (0.000001)\n",
      "87. feature 27 (0.000001)\n",
      "88. feature 35 (0.000001)\n",
      "89. feature 33 (0.000001)\n",
      "90. feature 39 (0.000001)\n",
      "91. feature 37 (0.000001)\n",
      "92. feature 52 (0.000000)\n",
      "93. feature 20 (0.000000)\n",
      "94. feature 57 (0.000000)\n",
      "95. feature 46 (0.000000)\n",
      "96. feature 25 (0.000000)\n",
      "97. feature 47 (0.000000)\n",
      "98. feature 50 (0.000000)\n",
      "99. feature 28 (0.000000)\n",
      "100. feature 79 (0.000000)\n",
      "101. feature 77 (0.000000)\n",
      "102. feature 54 (0.000000)\n",
      "103. feature 61 (0.000000)\n",
      "104. feature 81 (0.000000)\n",
      "105. feature 17 (0.000000)\n",
      "106. feature 68 (0.000000)\n",
      "107. feature 76 (0.000000)\n",
      "108. feature 56 (0.000000)\n",
      "109. feature 44 (0.000000)\n",
      "110. feature 83 (0.000000)\n",
      "111. feature 74 (0.000000)\n",
      "112. feature 38 (0.000000)\n",
      "113. feature 78 (0.000000)\n",
      "114. feature 34 (0.000000)\n",
      "115. feature 48 (0.000000)\n",
      "116. feature 59 (0.000000)\n",
      "117. feature 69 (0.000000)\n",
      "118. feature 55 (0.000000)\n",
      "119. feature 75 (0.000000)\n",
      "120. feature 58 (0.000000)\n",
      "121. feature 53 (0.000000)\n",
      "122. feature 26 (0.000000)\n",
      "123. feature 66 (0.000000)\n",
      "124. feature 80 (0.000000)\n",
      "125. feature 45 (0.000000)\n",
      "126. feature 73 (0.000000)\n",
      "127. feature 62 (0.000000)\n",
      "128. feature 72 (0.000000)\n",
      "129. feature 60 (0.000000)\n",
      "130. feature 82 (0.000000)\n",
      "131. feature 65 (0.000000)\n",
      "132. feature 70 (0.000000)\n",
      "133. feature 71 (0.000000)\n",
      "134. feature 63 (0.000000)\n",
      "Top 10 Feature\n",
      "Index(['Trips Last Hour', 'Trips Last Week (Same Hour)',\n",
      "       'Trips 2 Weeks Ago (Same Hour)', 'Fare Last Month',\n",
      "       'pickup_community_area_8', 'pickup_community_area_32',\n",
      "       'relative_humidity', 'temperature', 'Hour_7', 'wind_direction'],\n",
      "      dtype='object')\n",
      "Least Important 10 Feature\n",
      "Index(['pickup_community_area_37', 'pickup_community_area_65',\n",
      "       'pickup_community_area_54', 'pickup_community_area_64',\n",
      "       'pickup_community_area_52', 'pickup_community_area_74',\n",
      "       'pickup_community_area_57', 'pickup_community_area_62',\n",
      "       'pickup_community_area_63', 'pickup_community_area_55'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_Imp(rf4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rf4.pickle', 'wb') as f:\n",
    "    pickle.dump(rf4, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 128\n",
      "building tree 2 of 128\n",
      "building tree 3 of 128\n",
      "building tree 4 of 128\n",
      "building tree 5 of 128\n",
      "building tree 6 of 128\n",
      "building tree 7 of 128\n",
      "building tree 8 of 128\n",
      "building tree 9 of 128\n",
      "building tree 10 of 128\n",
      "building tree 11 of 128\n",
      "building tree 12 of 128\n",
      "building tree 13 of 128building tree 14 of 128\n",
      "building tree 15 of 128\n",
      "building tree 16 of 128\n",
      "building tree 17 of 128\n",
      "building tree 18 of 128building tree 19 of 128building tree 20 of 128\n",
      "\n",
      "\n",
      "\n",
      "building tree 21 of 128\n",
      "building tree 22 of 128\n",
      "building tree 23 of 128\n",
      "building tree 24 of 128\n",
      "building tree 25 of 128\n",
      "building tree 26 of 128\n",
      "building tree 27 of 128\n",
      "building tree 28 of 128\n",
      "building tree 29 of 128\n",
      "building tree 30 of 128\n",
      "building tree 31 of 128\n",
      "building tree 32 of 128\n",
      "building tree 33 of 128\n",
      "building tree 34 of 128\n",
      "building tree 35 of 128\n",
      "building tree 36 of 128\n",
      "building tree 37 of 128\n",
      "building tree 38 of 128\n",
      "building tree 39 of 128\n",
      "building tree 40 of 128\n",
      "building tree 41 of 128\n",
      "building tree 42 of 128\n",
      "building tree 43 of 128\n",
      "building tree 44 of 128\n",
      "building tree 45 of 128\n",
      "building tree 46 of 128\n",
      "building tree 47 of 128\n",
      "building tree 48 of 128\n",
      "building tree 49 of 128\n",
      "building tree 50 of 128\n",
      "building tree 51 of 128\n",
      "building tree 52 of 128\n",
      "building tree 53 of 128\n",
      "building tree 54 of 128\n",
      "building tree 55 of 128\n",
      "building tree 56 of 128\n",
      "building tree 57 of 128\n",
      "building tree 58 of 128\n",
      "building tree 59 of 128\n",
      "building tree 60 of 128\n",
      "building tree 61 of 128\n",
      "building tree 62 of 128\n",
      "building tree 63 of 128\n",
      "building tree 64 of 128\n",
      "building tree 65 of 128\n",
      "building tree 66 of 128\n",
      "building tree 67 of 128\n",
      "building tree 68 of 128\n",
      "building tree 69 of 128\n",
      "building tree 70 of 128\n",
      "building tree 71 of 128\n",
      "building tree 72 of 128\n",
      "building tree 73 of 128\n",
      "building tree 74 of 128\n",
      "building tree 75 of 128\n",
      "building tree 76 of 128\n",
      "building tree 77 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  4.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 78 of 128\n",
      "building tree 79 of 128\n",
      "building tree 80 of 128\n",
      "building tree 81 of 128\n",
      "building tree 82 of 128\n",
      "building tree 83 of 128\n",
      "building tree 84 of 128\n",
      "building tree 85 of 128\n",
      "building tree 86 of 128\n",
      "building tree 87 of 128\n",
      "building tree 88 of 128\n",
      "building tree 89 of 128\n",
      "building tree 90 of 128\n",
      "building tree 91 of 128\n",
      "building tree 92 of 128\n",
      "building tree 93 of 128\n",
      "building tree 94 of 128\n",
      "building tree 95 of 128\n",
      "building tree 96 of 128\n",
      "building tree 97 of 128\n",
      "building tree 98 of 128\n",
      "building tree 99 of 128\n",
      "building tree 100 of 128\n",
      "building tree 101 of 128\n",
      "building tree 102 of 128\n",
      "building tree 103 of 128\n",
      "building tree 104 of 128\n",
      "building tree 105 of 128\n",
      "building tree 106 of 128\n",
      "building tree 107 of 128\n",
      "building tree 108 of 128\n",
      "building tree 109 of 128\n",
      "building tree 110 of 128\n",
      "building tree 111 of 128\n",
      "building tree 112 of 128\n",
      "building tree 113 of 128\n",
      "building tree 114 of 128\n",
      "building tree 115 of 128\n",
      "building tree 116 of 128\n",
      "building tree 117 of 128\n",
      "building tree 118 of 128\n",
      "building tree 119 of 128\n",
      "building tree 120 of 128\n",
      "building tree 121 of 128\n",
      "building tree 122 of 128\n",
      "building tree 123 of 128\n",
      "building tree 124 of 128\n",
      "building tree 125 of 128\n",
      "building tree 126 of 128\n",
      "building tree 127 of 128\n",
      "building tree 128 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 122 out of 128 | elapsed:  9.0min remaining:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 128 out of 128 | elapsed:  9.1min finished\n"
     ]
    }
   ],
   "source": [
    "rf5 = RandomForestRegressor(n_estimators =128 ,bootstrap=True,min_samples_leaf=32,oob_score=True,n_jobs=-1,max_features=0.6,verbose=4)\n",
    "\n",
    "rf5=rf5.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:   59.7s remaining:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9590743083041773\n",
      "Test Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:   10.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9541365129824101\n",
      "MAE Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:  1.0min remaining:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:   10.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:   10.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9292325183903208\n",
      "MAE Test\n",
      "0.9811151432810741\n",
      "MSE Train\n",
      "10.988216566336707\n",
      "MSE Test\n",
      "12.052803947156724\n",
      "RMSE Train\n",
      "3.314847894902073\n",
      "RMSE Test\n",
      "3.471714842431147\n"
     ]
    }
   ],
   "source": [
    "metric(rf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 128\n",
      "building tree 2 of 128building tree 3 of 128\n",
      "building tree 4 of 128\n",
      "building tree 5 of 128\n",
      "building tree 6 of 128\n",
      "building tree 7 of 128\n",
      "\n",
      "building tree 8 of 128\n",
      "building tree 9 of 128building tree 10 of 128\n",
      "\n",
      "building tree 11 of 128\n",
      "building tree 12 of 128\n",
      "building tree 13 of 128building tree 14 of 128\n",
      "\n",
      "building tree 15 of 128building tree 16 of 128\n",
      "building tree 17 of 128\n",
      "\n",
      "building tree 18 of 128\n",
      "building tree 19 of 128\n",
      "building tree 20 of 128\n",
      "building tree 21 of 128\n",
      "building tree 22 of 128\n",
      "building tree 23 of 128\n",
      "building tree 24 of 128\n",
      "building tree 25 of 128\n",
      "building tree 26 of 128\n",
      "building tree 27 of 128\n",
      "building tree 28 of 128\n",
      "building tree 29 of 128\n",
      "building tree 30 of 128\n",
      "building tree 31 of 128\n",
      "building tree 32 of 128\n",
      "building tree 33 of 128\n",
      "building tree 34 of 128\n",
      "building tree 35 of 128\n",
      "building tree 36 of 128\n",
      "building tree 37 of 128\n",
      "building tree 38 of 128\n",
      "building tree 39 of 128\n",
      "building tree 40 of 128\n",
      "building tree 41 of 128\n",
      "building tree 42 of 128\n",
      "building tree 43 of 128\n",
      "building tree 44 of 128\n",
      "building tree 45 of 128\n",
      "building tree 46 of 128\n",
      "building tree 47 of 128\n",
      "building tree 48 of 128\n",
      "building tree 49 of 128\n",
      "building tree 50 of 128\n",
      "building tree 51 of 128\n",
      "building tree 52 of 128\n",
      "building tree 53 of 128\n",
      "building tree 54 of 128\n",
      "building tree 55 of 128\n",
      "building tree 56 of 128\n",
      "building tree 57 of 128\n",
      "building tree 58 of 128\n",
      "building tree 59 of 128\n",
      "building tree 60 of 128\n",
      "building tree 61 of 128\n",
      "building tree 62 of 128\n",
      "building tree 63 of 128\n",
      "building tree 64 of 128\n",
      "building tree 65 of 128\n",
      "building tree 66 of 128\n",
      "building tree 67 of 128\n",
      "building tree 68 of 128\n",
      "building tree 69 of 128\n",
      "building tree 70 of 128\n",
      "building tree 71 of 128\n",
      "building tree 72 of 128\n",
      "building tree 73 of 128\n",
      "building tree 74 of 128\n",
      "building tree 75 of 128\n",
      "building tree 76 of 128\n",
      "building tree 77 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 78 of 128\n",
      "building tree 79 of 128\n",
      "building tree 80 of 128\n",
      "building tree 81 of 128\n",
      "building tree 82 of 128\n",
      "building tree 83 of 128\n",
      "building tree 84 of 128\n",
      "building tree 85 of 128\n",
      "building tree 86 of 128\n",
      "building tree 87 of 128\n",
      "building tree 88 of 128\n",
      "building tree 89 of 128\n",
      "building tree 90 of 128\n",
      "building tree 91 of 128\n",
      "building tree 92 of 128\n",
      "building tree 93 of 128\n",
      "building tree 94 of 128\n",
      "building tree 95 of 128\n",
      "building tree 96 of 128\n",
      "building tree 97 of 128\n",
      "building tree 98 of 128\n",
      "building tree 99 of 128\n",
      "building tree 100 of 128\n",
      "building tree 101 of 128\n",
      "building tree 102 of 128\n",
      "building tree 103 of 128\n",
      "building tree 104 of 128\n",
      "building tree 105 of 128\n",
      "building tree 106 of 128\n",
      "building tree 107 of 128\n",
      "building tree 108 of 128\n",
      "building tree 109 of 128\n",
      "building tree 110 of 128\n",
      "building tree 111 of 128\n",
      "building tree 112 of 128\n",
      "building tree 113 of 128\n",
      "building tree 114 of 128\n",
      "building tree 115 of 128\n",
      "building tree 116 of 128\n",
      "building tree 117 of 128\n",
      "building tree 118 of 128\n",
      "building tree 119 of 128\n",
      "building tree 120 of 128\n",
      "building tree 121 of 128\n",
      "building tree 122 of 128\n",
      "building tree 123 of 128\n",
      "building tree 124 of 128\n",
      "building tree 125 of 128\n",
      "building tree 126 of 128\n",
      "building tree 127 of 128\n",
      "building tree 128 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 122 out of 128 | elapsed:  2.8min remaining:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 128 out of 128 | elapsed:  2.9min finished\n"
     ]
    }
   ],
   "source": [
    "rf6 = RandomForestRegressor(n_estimators =128 ,bootstrap=True,min_samples_leaf=32,oob_score=True,n_jobs=-1,max_features='sqrt',verbose=4)\n",
    "\n",
    "rf6=rf6.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:  1.2min remaining:    3.4s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9456311784690812\n",
      "Test Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:   12.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:   12.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9433632198185233\n",
      "MAE Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:  1.2min remaining:    3.4s\n",
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  58 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 122 out of 128 | elapsed:   12.3s remaining:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0165104354305565\n",
      "MAE Test\n",
      "1.031301953914085\n",
      "MSE Train\n",
      "14.58442133662095\n",
      "MSE Test\n",
      "14.875303455549796\n",
      "RMSE Train\n",
      "3.8189555295422006\n",
      "RMSE Test\n",
      "3.8568514951382036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 128 out of 128 | elapsed:   12.5s finished\n"
     ]
    }
   ],
   "source": [
    "metric(rf6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After changing hyper-parameters many times we found out that these are best for our dataset\n",
    "\n",
    "n_estimators = 256,bootstrap=True,min_samples_leaf=64,oob_score=True,n_jobs=-1,\n",
    "                           max_features=0.4,verbose=4,min_samples_split=64 \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
