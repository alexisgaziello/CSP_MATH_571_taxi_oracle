{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging of Weather, Holidays and Taxi Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    sep = '\\\\'\n",
    "elif os.name == 'posix':\n",
    "    sep = '/'\n",
    "else:\n",
    "    print(f'What is this OS? {os.name}')\n",
    "\n",
    "path = os.getcwd()\n",
    "path_datasets = path[:-len(f'Code{sep}src{sep}project_CSP_MATH_571')] + f'DataSets{sep}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Holidays data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadHolidaysData(verbose = True):\n",
    "    if verbose == True:\n",
    "        time_start = time.time()\n",
    "    \n",
    "    df = pd.read_csv('holiday_df.csv', delimiter=',')\n",
    "    df = df[['date', 'daytype']].drop_duplicates()\n",
    "    df_2016_2019 = df[df['date'].str.contains('2019|2018|2017|2016')]\n",
    "    df_date = df_2016_2019['date'].str.split(' ').apply(lambda x : x[0])\n",
    "    \n",
    "    dates = pd.to_datetime(df_date)\n",
    "    df_2016_2019['date'] = dates.dt.strftime('%m/%d/%Y')\n",
    "    #assert(len(df_2016_2019) == ((365*3)+366)) # Check there are no missing values\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('time taken to load Data:', time.time() - time_start, 'seconds')\n",
    "        \n",
    "    return df_2016_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to load Data: 0.03300118446350098 seconds\n"
     ]
    }
   ],
   "source": [
    "df_holidays = loadHolidaysData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>daytype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/2017</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/03/2017</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/04/2017</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/05/2017</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/06/2017</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>12/26/2019</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>12/27/2019</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>12/28/2019</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>12/29/2019</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>12/30/2019</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1093 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date daytype\n",
       "0     01/02/2017       U\n",
       "1     01/03/2017       W\n",
       "2     01/04/2017       W\n",
       "3     01/05/2017       W\n",
       "4     01/06/2017       W\n",
       "...          ...     ...\n",
       "1088  12/26/2019       W\n",
       "1089  12/27/2019       W\n",
       "1090  12/28/2019       A\n",
       "1091  12/29/2019       U\n",
       "1092  12/30/2019       W\n",
       "\n",
       "[1093 rows x 2 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       0\n",
       "daytype    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_holidays.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTaxiData(verbose = True):\n",
    "    if verbose == True:\n",
    "        time_start = time.time()\n",
    "        \n",
    "#     df_taxi = pd.read_csv(path_datasets + 'jan-ap19.csv', delimiter=',')\n",
    "#     df_taxi_1 = pd.read_csv(path_datasets + 'jan-may17.csv', delimiter=',')\n",
    "#     df_taxi_2 = pd.read_csv(path_datasets + 'june17-feb18.csv', delimiter=',')\n",
    "#     df_taxi_3 = pd.read_csv(path_datasets + 'mar-aug18.csv', delimiter=',')\n",
    "#     df_taxi_4 = pd.read_csv(path_datasets + 'may-nov19.csv', delimiter=',')\n",
    "#     df_taxi_5 = pd.read_csv(path_datasets + 'sep-dec18.csv', delimiter=',')\n",
    "\n",
    "#     df_taxi_total = pd.concat([df_taxi, df_taxi_1, df_taxi_2, df_taxi_3, df_taxi_4, df_taxi_5])\n",
    "    df_taxi_total=pd.read_csv(\"taxi_clean_df.csv\",delimiter=',')\n",
    "    \n",
    "    df_date = df_taxi_total['trip_start_timestamp'].str.split(' ').apply(lambda x : x[0])\n",
    "    \n",
    "    dates = pd.to_datetime(df_date)\n",
    "    \n",
    "    df_taxi_total['date'] = dates.dt.strftime('%m/%d/%Y')\n",
    "    \n",
    "    \n",
    "    if verbose == True:\n",
    "        print('time taken to load Data:', time.time() - time_start, 'seconds')\n",
    "    \n",
    "    return df_taxi_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to load Data: 70.46820855140686 seconds\n"
     ]
    }
   ],
   "source": [
    "df_taxi = loadTaxiData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <th>unique_key</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>trip_start_timestamp.1</th>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_community_area</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>fare</th>\n",
       "      <th>tips</th>\n",
       "      <th>extras</th>\n",
       "      <th>trip_total</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-19 13:30:00</td>\n",
       "      <td>977e465c878cd5337c2215e291ecf091cf2ef4a6</td>\n",
       "      <td>84dab24222c24f99f6c543a5d02e5b47940df071fef3ed...</td>\n",
       "      <td>2019-01-19 13:30:00</td>\n",
       "      <td>2019-01-19 13:30:00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Cash</td>\n",
       "      <td>01/19/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-24 07:15:00</td>\n",
       "      <td>f9eb08f49f09e56188333a95bea1d9d7220a79a9</td>\n",
       "      <td>15ba3f3c77572f9fe6f7cd47e70fa31af10194449cc975...</td>\n",
       "      <td>2019-01-24 07:15:00</td>\n",
       "      <td>2019-01-24 07:30:00</td>\n",
       "      <td>328.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>01/24/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-07 21:45:00</td>\n",
       "      <td>6c40ff49c9e05b30bef35ba2c0c0639fe3506127</td>\n",
       "      <td>b259515344f28837cc7546ff185da59066c4aa0c2ad490...</td>\n",
       "      <td>2019-02-07 21:45:00</td>\n",
       "      <td>2019-02-07 21:45:00</td>\n",
       "      <td>213.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Cash</td>\n",
       "      <td>02/07/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-20 18:00:00</td>\n",
       "      <td>4c0c28580737e54f83246154655e06344e27897c</td>\n",
       "      <td>6551ba527f916e0b8187165d7e61705fc2641c9b3afd69...</td>\n",
       "      <td>2019-02-20 18:00:00</td>\n",
       "      <td>2019-02-20 18:00:00</td>\n",
       "      <td>348.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>02/20/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-13 08:30:00</td>\n",
       "      <td>b01e270fa78b2b711a606dfd41bc7bb10ce2e460</td>\n",
       "      <td>98218edd8c1afe2aa636693c931d34e5bdd76df10e1b6a...</td>\n",
       "      <td>2019-02-13 08:30:00</td>\n",
       "      <td>2019-02-13 08:45:00</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>02/13/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trip_start_timestamp                                unique_key  \\\n",
       "0  2019-01-19 13:30:00  977e465c878cd5337c2215e291ecf091cf2ef4a6   \n",
       "1  2019-01-24 07:15:00  f9eb08f49f09e56188333a95bea1d9d7220a79a9   \n",
       "2  2019-02-07 21:45:00  6c40ff49c9e05b30bef35ba2c0c0639fe3506127   \n",
       "3  2019-02-20 18:00:00  4c0c28580737e54f83246154655e06344e27897c   \n",
       "4  2019-02-13 08:30:00  b01e270fa78b2b711a606dfd41bc7bb10ce2e460   \n",
       "\n",
       "                                             taxi_id trip_start_timestamp.1  \\\n",
       "0  84dab24222c24f99f6c543a5d02e5b47940df071fef3ed...    2019-01-19 13:30:00   \n",
       "1  15ba3f3c77572f9fe6f7cd47e70fa31af10194449cc975...    2019-01-24 07:15:00   \n",
       "2  b259515344f28837cc7546ff185da59066c4aa0c2ad490...    2019-02-07 21:45:00   \n",
       "3  6551ba527f916e0b8187165d7e61705fc2641c9b3afd69...    2019-02-20 18:00:00   \n",
       "4  98218edd8c1afe2aa636693c931d34e5bdd76df10e1b6a...    2019-02-13 08:30:00   \n",
       "\n",
       "    trip_end_timestamp  trip_seconds  trip_miles  pickup_community_area  \\\n",
       "0  2019-01-19 13:30:00          19.0         0.1                     14   \n",
       "1  2019-01-24 07:30:00         328.0         1.1                     14   \n",
       "2  2019-02-07 21:45:00         213.0         0.9                     14   \n",
       "3  2019-02-20 18:00:00         348.0         0.9                     14   \n",
       "4  2019-02-13 08:45:00         435.0         0.8                     14   \n",
       "\n",
       "   dropoff_community_area  fare  tips  extras  trip_total payment_type  \\\n",
       "0                      14   3.5   0.0     0.0         3.5         Cash   \n",
       "1                      14   6.0   0.0     0.0         6.0         Cash   \n",
       "2                      14   5.5   0.0     0.0         5.5         Cash   \n",
       "3                      14   6.0   0.0     0.0         6.0         Cash   \n",
       "4                      14   6.0   0.0     0.0         6.0         Cash   \n",
       "\n",
       "         date  \n",
       "0  01/19/2019  \n",
       "1  01/24/2019  \n",
       "2  02/07/2019  \n",
       "3  02/20/2019  \n",
       "4  02/13/2019  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trip_start_timestamp      0\n",
       "unique_key                0\n",
       "taxi_id                   0\n",
       "trip_start_timestamp.1    0\n",
       "trip_end_timestamp        0\n",
       "trip_seconds              0\n",
       "trip_miles                0\n",
       "pickup_community_area     0\n",
       "dropoff_community_area    0\n",
       "fare                      0\n",
       "tips                      0\n",
       "extras                    0\n",
       "trip_total                0\n",
       "payment_type              0\n",
       "date                      0\n",
       "DateTime                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSpaciatedTime():\n",
    "\n",
    "    def datetime_range(start, end, delta):\n",
    "        current = start\n",
    "        while current < end:\n",
    "            yield current\n",
    "            current += delta\n",
    "\n",
    "    dts = [dt.strftime('%Y-%m-%d %H:%M:%S+00:00') for dt in \n",
    "          datetime_range(datetime(2017,1,1,1), datetime(2020,1,1,0), \n",
    "                         timedelta(minutes = 15))]\n",
    "    return dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildNewWeather(dts):\n",
    "    \n",
    "    df_weather_new = pd.DataFrame(dts, columns = ['DateTime'])\n",
    "    df_weather_new['DateTime'] = pd.to_datetime(df_weather_new['DateTime'])\n",
    "    df_weather_new['temperature'] = np.nan\n",
    "    df_weather_new['relative_humidity'] = np.nan\n",
    "    df_weather_new['wind_direction'] = np.nan\n",
    "    df_weather_new['wind_speed'] = np.nan\n",
    "    df_weather_new['precipitation'] = np.nan\n",
    "    df_weather_new['sky_level'] = np.nan\n",
    "    \n",
    "    return df_weather_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNewWeather(df_weather_new, df_weather, verbose = True):\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('----------------- Program to fill the weather -----------------')\n",
    "        print()\n",
    "        counter = 0\n",
    "        time_start = time.time()\n",
    "        \n",
    "    position = 0\n",
    "\n",
    "    for i in range(0, len(df_weather_new)):\n",
    "\n",
    "        datetime = df_weather_new['DateTime'].iloc[i]\n",
    "\n",
    "        found = False\n",
    "        while (found == False):\n",
    "            if position == len(df_weather) - 1: # in case df_weather_new has newer dates than df_weather\n",
    "                found = True\n",
    "            elif ((datetime < df_weather['DateTime'].iloc[position + 1]) &  (datetime >= df_weather['DateTime'].iloc[position])):\n",
    "                df_weather_new['temperature'].iloc[i] = df_weather['temperature'].iloc[position]\n",
    "                df_weather_new['relative_humidity'].iloc[i] = df_weather['relative_humidity'].iloc[position]\n",
    "                df_weather_new['wind_direction'].iloc[i] = df_weather['wind_direction'].iloc[position]\n",
    "                df_weather_new['wind_speed'].iloc[i] = df_weather['wind_speed'].iloc[position]\n",
    "                df_weather_new['precipitation'].iloc[i] = df_weather['precipitation'].iloc[position]\n",
    "                df_weather_new['sky_level'].iloc[i] = df_weather['sky_level'].iloc[position]\n",
    "                found = True\n",
    "            else:\n",
    "                position += 1\n",
    "                \n",
    "        if verbose == True:\n",
    "            if i % 5000 == 0:\n",
    "                print('The program has done', counter *5000, 'iterations')\n",
    "                print('time taken till now: ', time.time() - time_start, 'seconds')\n",
    "                print()\n",
    "                counter +=1\n",
    "            \n",
    "    return df_weather_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAndConvertWeather():\n",
    "    df_weather=pd.read_csv('weather_df.csv', delimiter=',')\n",
    "    \n",
    "    del df_weather['station']\n",
    "    \n",
    "    # In order to have a column with localization. Needed for merging.\n",
    "    df_weather['DateTime'] = pd.to_datetime(df_weather['datetime'])\n",
    "    df_weather = df_weather.set_index('DateTime')\n",
    "    df_weather = df_weather.tz_localize('UTC')\n",
    "    df_weather = df_weather.reset_index()\n",
    "    \n",
    "    dts = createSpaciatedTime()\n",
    "    \n",
    "    [datetime.strptime(x, '%Y-%m-%d %H:%M:%S+00:00') for x in dts]\n",
    "    \n",
    "    df_weather_new = buildNewWeather(dts)\n",
    "    \n",
    "    df_weather_new = fillNewWeather(df_weather_new, df_weather, verbose = True)\n",
    "    \n",
    "    \n",
    "    return df_weather_new.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Program to fill the weather -----------------\n",
      "\n",
      "The program has done 0 iterations\n",
      "time taken till now:  0.01299595832824707 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iconsense\\Anaconda3\\envs\\abhishek\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program has done 5000 iterations\n",
      "time taken till now:  6.891345739364624 seconds\n",
      "\n",
      "The program has done 10000 iterations\n",
      "time taken till now:  13.733802556991577 seconds\n",
      "\n",
      "The program has done 15000 iterations\n",
      "time taken till now:  20.546186685562134 seconds\n",
      "\n",
      "The program has done 20000 iterations\n",
      "time taken till now:  27.441372632980347 seconds\n",
      "\n",
      "The program has done 25000 iterations\n",
      "time taken till now:  34.265355825424194 seconds\n",
      "\n",
      "The program has done 30000 iterations\n",
      "time taken till now:  41.06945013999939 seconds\n",
      "\n",
      "The program has done 35000 iterations\n",
      "time taken till now:  47.84544587135315 seconds\n",
      "\n",
      "The program has done 40000 iterations\n",
      "time taken till now:  54.589452028274536 seconds\n",
      "\n",
      "The program has done 45000 iterations\n",
      "time taken till now:  61.325480461120605 seconds\n",
      "\n",
      "The program has done 50000 iterations\n",
      "time taken till now:  68.07650089263916 seconds\n",
      "\n",
      "The program has done 55000 iterations\n",
      "time taken till now:  74.81245851516724 seconds\n",
      "\n",
      "The program has done 60000 iterations\n",
      "time taken till now:  81.5494658946991 seconds\n",
      "\n",
      "The program has done 65000 iterations\n",
      "time taken till now:  88.55146718025208 seconds\n",
      "\n",
      "The program has done 70000 iterations\n",
      "time taken till now:  95.48346590995789 seconds\n",
      "\n",
      "The program has done 75000 iterations\n",
      "time taken till now:  102.20903706550598 seconds\n",
      "\n",
      "The program has done 80000 iterations\n",
      "time taken till now:  108.94860601425171 seconds\n",
      "\n",
      "The program has done 85000 iterations\n",
      "time taken till now:  115.69061827659607 seconds\n",
      "\n",
      "The program has done 90000 iterations\n",
      "time taken till now:  122.42519855499268 seconds\n",
      "\n",
      "The program has done 95000 iterations\n",
      "time taken till now:  129.14822340011597 seconds\n",
      "\n",
      "The program has done 100000 iterations\n",
      "time taken till now:  135.82723116874695 seconds\n",
      "\n",
      "The program has done 105000 iterations\n",
      "time taken till now:  142.4712347984314 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weather = loadAndConvertWeather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime             0\n",
       "temperature          0\n",
       "relative_humidity    0\n",
       "wind_direction       0\n",
       "wind_speed           0\n",
       "precipitation        0\n",
       "sky_level            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDataframes(df_taxi, df_weather, df_holidays, verbose = True):\n",
    "    \n",
    "    if verbose == True:\n",
    "        time_start = time.time()\n",
    "    \n",
    "    df_taxi['DateTime'] = pd.to_datetime(df_taxi['trip_start_timestamp'], utc = True)\n",
    "    \n",
    "    df_taxi_holidays = df_taxi.merge(df_holidays, how = 'left', on = 'date')\n",
    "\n",
    "    df_taxi_holidays_weather = df_taxi_holidays.merge(df_weather, how = 'left', on = 'DateTime')\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('time taken to merge Data:', time.time() - time_start, 'seconds')\n",
    "    \n",
    "    return df_taxi_holidays_weather\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to merge Data: 10.236896753311157 seconds\n"
     ]
    }
   ],
   "source": [
    "df_merged = mergeDataframes(df_taxi,df_weather, df_holidays, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7069319"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(r'C:/Users/Iconsense/abhishek/taxi/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
