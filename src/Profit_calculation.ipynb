{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model_neural_network.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model_neural_network.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(date):\n",
    "    \n",
    "    def dummie_and_drop(df, name):\n",
    "        # Creates a dummy variable, concatenates it and finally drops the original categorical variable.\n",
    "        # In order not to have redundant variables, one of the dummy variables is dropped too\n",
    "        dummies = pd.get_dummies(df[name]).rename(columns = lambda x: name + '_' + str(x))\n",
    "        dummies = dummies.drop(dummies.columns[-1], axis = 1)\n",
    "        df = pd.concat([df, dummies], axis = 1)\n",
    "        df.drop(columns = [name], inplace=True, axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def convert_to_categorical(df, categorical_variables, categories, need_pickup = True):\n",
    "        \"\"\" \n",
    "        The dataframe's selected variables are converted to categorical, and each variable's categories are also specified.\n",
    "        It is also specified if the \"pickup community area\" has to be converted into categorical or no. If it is not \n",
    "        converted into categorical it is because it's not going to be used in the model.            \n",
    "        \"\"\"\n",
    "        \n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            df.drop(columns = ['pickup_community_area'], inplace = True, axis = 1)\n",
    "            begin = 1\n",
    "        \n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def load(name, date, need_pickup = False, drop_correlated = False):\n",
    "    \n",
    "        # This parameter has to be set to True if the \"pickup_community_area\" variable is needed in the model\n",
    "        \n",
    "\n",
    "        # Load needed dataset and choose the useful columns\n",
    "        df = pd.read_csv(name) #'dataset_train.csv')\n",
    "        df = df[df['trip_start_timestamp'].str.slice(start = 0, stop = 13) == date]\n",
    "        x = df[['pickup_community_area' ,'temperature', 'relative_humidity', 'wind_direction', 'wind_speed', 'precipitation_cat', \n",
    "                'sky_level', 'daytype', 'Day Name', 'Month', 'Hour', 'Fare Last Month', 'Trips Last Hour',\n",
    "                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)', 'Quarter', 'Year', 'trip_start_timestamp']]\n",
    "\n",
    "        # Convert the categorical variables\n",
    "        categorical_variables = ['pickup_community_area', 'daytype', 'sky_level', 'Day Name', 'Month','Hour', 'Year']\n",
    "        categories = [[*(range(1,78))], ['U', 'W', 'A'], ['OVC', 'BKN', 'SCT', 'FEW', 'CLR', 'VV '], \n",
    "                      ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "                      [*(range(1,13))], [*(range(0, 24))], ['2017', '2018', '2019']]\n",
    "\n",
    "        x = convert_to_categorical(x, categorical_variables, categories, need_pickup = need_pickup)\n",
    "\n",
    "        \n",
    "        # Make dummy variables with the categorical ones\n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            begin = 1\n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            x = dummie_and_drop(x, name = categorical_variables[i])\n",
    "        \n",
    "        \n",
    "        \n",
    "        y = df['Trips'].to_numpy()\n",
    "\n",
    "        if need_pickup == False:\n",
    "            # If we don't need the pickup, it means this is Neural Network case. Therefore we have to modify Y, in order\n",
    "            # to have \"n_areas\" outputs per input (because there are \"n_areas\" regressions per input)\n",
    "            x = x.groupby(by = 'trip_start_timestamp').mean()\n",
    "            n_areas = 77\n",
    "            y = np.reshape(y, [-1, n_areas]) # If \n",
    "        else:\n",
    "            x.drop(columns = ['trip_start_timestamp'], inplace = True, axis = 1)\n",
    "        \n",
    "        if drop_correlated:\n",
    "            x.drop(columns = ['Trips Last Week (Same Hour)'], inplace = True, axis = 1)\n",
    "            x.drop(columns = ['Trips 2 Weeks Ago (Same Hour)'], inplace = True, axis = 1)\n",
    "\n",
    "        x = x.to_numpy()\n",
    "        \n",
    "        return (x,y)   \n",
    "    \n",
    "\n",
    "    need_pickup = False \n",
    "    drop_correlated = False\n",
    "    \n",
    "\n",
    "    name_test = 'dataset_test.csv'\n",
    "    x_test, y_test = load(name_test, date, need_pickup, drop_correlated)\n",
    "    \n",
    "    \n",
    "    return (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs_julen\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Programs_julen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "date = '2019-11-12 14'\n",
    "date_test = '2019-11-12 15' # The next hour\n",
    "x_test, y_test = load_data(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous Disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi = pd.read_csv('may-nov19.csv')\n",
    "date = '2019-11-12 14'\n",
    "date_test = '2019-11-12 15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the columns needed\n",
    "df_taxi = df_taxi[['taxi_id', 'trip_end_timestamp','dropoff_community_area', 'trip_start_timestamp']]\n",
    "# Modify Trip_end_timestamp and sort dataframe\n",
    "# df_taxi['trip_end_timestamp'] = df_taxi['trip_end_timestamp'].str.slice(start= 0, stop = 19)\n",
    "# df_taxi['trip_start_timestamp'] = df_taxi['trip_start_timestamp'].str.slice(start= 0, stop = 19)\n",
    "\n",
    "df_busy = df_taxi[df_taxi['trip_start_timestamp'].str.slice(start = 0, stop = 13) == date]\n",
    "df_arrive = df_taxi[(df_taxi['trip_start_timestamp'].str.slice(start = 0, stop = 16) == date_test + ':00') | (df_taxi['trip_start_timestamp'].str.slice(start = 0, stop = 16) == date_test + ':15')]\n",
    "df_date = df_taxi[df_taxi['trip_end_timestamp'].str.slice(start = 0, stop = 13) == date]\n",
    "\n",
    "df_date = df_date.sort_values(by = ['trip_end_timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trips:  464\n",
      "number of different taxis:  277\n",
      "number of missing values:  77\n",
      "\n",
      "------ Deleting missing values ------\n",
      "\n",
      "number of trips:  387\n",
      "number of different taxis:  228\n",
      "number of missing values:  0\n",
      "\n",
      "------ Deleting duplicated values ------\n",
      "\n",
      "number of trips:  228\n",
      "number of different taxis:  228\n",
      "number of missing values:  0\n"
     ]
    }
   ],
   "source": [
    "print('number of trips: ', df_date.shape[0])\n",
    "print('number of different taxis: ', len(df_date['taxi_id'].unique()))\n",
    "print('number of missing values: ', sum(df_date['dropoff_community_area'].isnull())) # Even if it is null, in a real case we would have the data\n",
    "print()\n",
    "print('------ Deleting missing values ------')\n",
    "df_date = df_date.dropna()\n",
    "print()\n",
    "print('number of trips: ', df_date.shape[0])\n",
    "print('number of different taxis: ', len(df_date['taxi_id'].unique()))\n",
    "print('number of missing values: ', sum(df_date['dropoff_community_area'].isnull()))\n",
    "print()\n",
    "print('------ Deleting duplicated values ------')\n",
    "print()\n",
    "df_date.drop_duplicates(subset = 'taxi_id', keep = 'last', inplace = True)\n",
    "print('number of trips: ', df_date.shape[0])\n",
    "print('number of different taxis: ', len(df_date['taxi_id'].unique()))\n",
    "print('number of missing values: ', sum(df_date['dropoff_community_area'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs_julen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# df_date.drop_duplicates(subset = 'taxi_id', keep = 'last', inplace = True)\n",
    "df_busy.drop_duplicates(subset = 'taxi_id', keep = 'last', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_delete = []\n",
    "\n",
    "for i in range(0, len(df_date)):\n",
    "    taxi = df_date[['taxi_id', 'trip_end_timestamp']].iloc[i]\n",
    "#     print(taxi)\n",
    "    for j in range(0, len(df_busy)):\n",
    "        taxi_busy = df_busy[['taxi_id', 'trip_start_timestamp']].iloc[j]\n",
    "        if (str(taxi_busy['taxi_id']) == str(taxi['taxi_id']) and (str(taxi_busy['trip_start_timestamp']) > str(taxi['trip_end_timestamp']))):\n",
    "            index = taxi.name\n",
    "            index_delete.append(index)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>622029</th>\n",
       "      <td>180309cc29892cd16348ef74d7dd6f33af87e585a29b62...</td>\n",
       "      <td>2019-11-12 14:00:00 UTC</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2019-11-12 13:45:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621788</th>\n",
       "      <td>41296974f291ee1728c72308233ea977759ee4314b08c9...</td>\n",
       "      <td>2019-11-12 14:00:00 UTC</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-11-12 13:45:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410653</th>\n",
       "      <td>1d6029b251dadc15c2cfb884ba055cef1b39e07432f06f...</td>\n",
       "      <td>2019-11-12 14:00:00 UTC</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2019-11-12 14:00:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616802</th>\n",
       "      <td>8d7a84d700f39f9b122b67d40075873e4de4a5f792b95d...</td>\n",
       "      <td>2019-11-12 14:00:00 UTC</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2019-11-12 14:00:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427139</th>\n",
       "      <td>3cde16a0a5352e50a25619d54c0c3bb6343327bc47c97a...</td>\n",
       "      <td>2019-11-12 14:00:00 UTC</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2019-11-12 13:45:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749153</th>\n",
       "      <td>22b403ba1c4de25cb19049e9c08b6d1339a9eea3ec06f9...</td>\n",
       "      <td>2019-11-12 14:45:00 UTC</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2019-11-12 14:30:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747330</th>\n",
       "      <td>237a0889e04b6ab9609738d8b35485bce00cf600493d4e...</td>\n",
       "      <td>2019-11-12 14:45:00 UTC</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2019-11-12 14:30:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390355</th>\n",
       "      <td>f184219b3bc8cf9ef5f1417bc53dad6e4e6babe987f67b...</td>\n",
       "      <td>2019-11-12 14:45:00 UTC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-11-12 14:00:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432785</th>\n",
       "      <td>937aef1d267e19d4c5760039dc79f4df2c977744679d14...</td>\n",
       "      <td>2019-11-12 14:45:00 UTC</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2019-11-12 14:30:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437968</th>\n",
       "      <td>693cedd88daba67f64a5d6c8423213fb1b897508578478...</td>\n",
       "      <td>2019-11-12 14:45:00 UTC</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2019-11-12 14:30:00 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   taxi_id  \\\n",
       "622029   180309cc29892cd16348ef74d7dd6f33af87e585a29b62...   \n",
       "621788   41296974f291ee1728c72308233ea977759ee4314b08c9...   \n",
       "1410653  1d6029b251dadc15c2cfb884ba055cef1b39e07432f06f...   \n",
       "616802   8d7a84d700f39f9b122b67d40075873e4de4a5f792b95d...   \n",
       "1427139  3cde16a0a5352e50a25619d54c0c3bb6343327bc47c97a...   \n",
       "...                                                    ...   \n",
       "749153   22b403ba1c4de25cb19049e9c08b6d1339a9eea3ec06f9...   \n",
       "747330   237a0889e04b6ab9609738d8b35485bce00cf600493d4e...   \n",
       "1390355  f184219b3bc8cf9ef5f1417bc53dad6e4e6babe987f67b...   \n",
       "1432785  937aef1d267e19d4c5760039dc79f4df2c977744679d14...   \n",
       "1437968  693cedd88daba67f64a5d6c8423213fb1b897508578478...   \n",
       "\n",
       "              trip_end_timestamp  dropoff_community_area  \\\n",
       "622029   2019-11-12 14:00:00 UTC                     8.0   \n",
       "621788   2019-11-12 14:00:00 UTC                    11.0   \n",
       "1410653  2019-11-12 14:00:00 UTC                     8.0   \n",
       "616802   2019-11-12 14:00:00 UTC                    32.0   \n",
       "1427139  2019-11-12 14:00:00 UTC                     8.0   \n",
       "...                          ...                     ...   \n",
       "749153   2019-11-12 14:45:00 UTC                    37.0   \n",
       "747330   2019-11-12 14:45:00 UTC                    33.0   \n",
       "1390355  2019-11-12 14:45:00 UTC                     2.0   \n",
       "1432785  2019-11-12 14:45:00 UTC                    32.0   \n",
       "1437968  2019-11-12 14:45:00 UTC                    32.0   \n",
       "\n",
       "            trip_start_timestamp  \n",
       "622029   2019-11-12 13:45:00 UTC  \n",
       "621788   2019-11-12 13:45:00 UTC  \n",
       "1410653  2019-11-12 14:00:00 UTC  \n",
       "616802   2019-11-12 14:00:00 UTC  \n",
       "1427139  2019-11-12 13:45:00 UTC  \n",
       "...                          ...  \n",
       "749153   2019-11-12 14:30:00 UTC  \n",
       "747330   2019-11-12 14:30:00 UTC  \n",
       "1390355  2019-11-12 14:00:00 UTC  \n",
       "1432785  2019-11-12 14:30:00 UTC  \n",
       "1437968  2019-11-12 14:30:00 UTC  \n",
       "\n",
       "[202 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_date.drop(index_delete, inplace = True)\n",
    "df_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset df_taxi clean!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have to find the taxis that end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs_julen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Programs_julen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(175, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arrive.dropna(inplace = True)\n",
    "df_arrive.drop_duplicates(subset = 'taxi_id', keep = 'first', inplace = True)\n",
    "\n",
    "df_arrive.shape\n",
    "# df_date = df_date.drop_duplicates(subset = 'taxi_id', keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ammount of taxis not moving:  202\n",
      "Ammount of taxis arriving:  175\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32.0</th>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33.0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76.0</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77.0</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        taxi_id  trip_end_timestamp  trip_start_timestamp\n",
       "dropoff_community_area                                                   \n",
       "1.0                           3                   3                     3\n",
       "2.0                          11                  11                    11\n",
       "3.0                           7                   7                     7\n",
       "4.0                           3                   3                     3\n",
       "5.0                           4                   4                     4\n",
       "6.0                          23                  23                    23\n",
       "7.0                          16                  16                    16\n",
       "8.0                          78                  78                    78\n",
       "9.0                           1                   1                     1\n",
       "10.0                          4                   4                     4\n",
       "11.0                          1                   1                     1\n",
       "12.0                          1                   1                     1\n",
       "13.0                          3                   3                     3\n",
       "14.0                          3                   3                     3\n",
       "16.0                          4                   4                     4\n",
       "17.0                          3                   3                     3\n",
       "21.0                          3                   3                     3\n",
       "22.0                          2                   2                     2\n",
       "23.0                          2                   2                     2\n",
       "24.0                          7                   7                     7\n",
       "27.0                          4                   4                     4\n",
       "28.0                         24                  24                    24\n",
       "29.0                          2                   2                     2\n",
       "30.0                          1                   1                     1\n",
       "32.0                         76                  76                    76\n",
       "33.0                          8                   8                     8\n",
       "34.0                          1                   1                     1\n",
       "35.0                          1                   1                     1\n",
       "36.0                          2                   2                     2\n",
       "37.0                          3                   3                     3\n",
       "38.0                          1                   1                     1\n",
       "39.0                          1                   1                     1\n",
       "41.0                          3                   3                     3\n",
       "42.0                          3                   3                     3\n",
       "43.0                          4                   4                     4\n",
       "44.0                          1                   1                     1\n",
       "46.0                          1                   1                     1\n",
       "49.0                          4                   4                     4\n",
       "51.0                          1                   1                     1\n",
       "53.0                          3                   3                     3\n",
       "56.0                          4                   4                     4\n",
       "58.0                          2                   2                     2\n",
       "59.0                          2                   2                     2\n",
       "68.0                          1                   1                     1\n",
       "69.0                          1                   1                     1\n",
       "70.0                          2                   2                     2\n",
       "71.0                          1                   1                     1\n",
       "72.0                          2                   2                     2\n",
       "75.0                          2                   2                     2\n",
       "76.0                         25                  25                    25\n",
       "77.0                         12                  12                    12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Ammount of taxis not moving: ', df_date['dropoff_community_area'].shape[0])\n",
    "print('Ammount of taxis arriving: ', df_arrive['dropoff_community_area'].shape[0])\n",
    "df_total = pd.concat([df_date, df_arrive])\n",
    "df_total.groupby(by = 'dropoff_community_area').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Take out from df_date all the taxis that are actually not available. How to do this:\n",
    "    - Take all the taxis that are in the df_busy dataset.\n",
    "    - If there are duplicates: Check if taxi gets busy after being free for the last time\n",
    "- Put taxis that arrive to the community area before the half of the next hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'2019-11-12 10:45' > '2019-11-12 10:45' # It recognizes this kind of notation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
