{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to get reproducible results\n",
    "\n",
    "# Seed value (can actually be different for each attribution step)\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    def dummie_and_drop(df, name):\n",
    "        # Creates a dummy variable, concatenates it and finally drops the original categorical variable.\n",
    "        # In order not to have redundant variables, one of the dummy variables is dropped too\n",
    "        dummies = pd.get_dummies(df[name]).rename(columns = lambda x: name + '_' + str(x))\n",
    "        dummies = dummies.drop(dummies.columns[-1], axis = 1)\n",
    "        df = pd.concat([df, dummies], axis = 1)\n",
    "        df.drop(columns = [name], inplace=True, axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def convert_to_categorical(df, categorical_variables, categories, need_pickup = True):\n",
    "        \"\"\" \n",
    "        The dataframe's selected variables are converted to categorical, and each variable's categories are also specified.\n",
    "        It is also specified if the \"pickup community area\" has to be converted into categorical or no. If it is not \n",
    "        converted into categorical it is because it's not going to be used in the model.            \n",
    "        \"\"\"\n",
    "        \n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            df.drop(columns = ['pickup_community_area'], inplace = True, axis = 1)\n",
    "            begin = 1\n",
    "        \n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def load(name, need_pickup = False, drop_correlated = False):\n",
    "    \n",
    "        # This parameter has to be set to True if the \"pickup_community_area\" variable is needed in the model\n",
    "        \n",
    "\n",
    "        # Load needed dataset and choose the useful columns\n",
    "        df = pd.read_csv(name) #'dataset_train.csv')\n",
    "        x = df[['pickup_community_area' ,'temperature', 'relative_humidity', 'wind_direction', 'wind_speed', 'precipitation_cat', \n",
    "                'sky_level', 'daytype', 'Day Name', 'Month', 'Hour', 'Fare Last Month', 'Trips Last Hour',\n",
    "                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)', 'Quarter', 'Year']]\n",
    "\n",
    "        # Convert the categorical variables\n",
    "        categorical_variables = ['pickup_community_area', 'daytype', 'sky_level', 'Day Name', 'Month','Hour', 'Year']\n",
    "        categories = [[*(range(1,78))], ['U', 'W', 'A'], ['OVC', 'BKN', 'SCT', 'FEW', 'CLR', 'VV '], \n",
    "                      ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "                      [*(range(1,13))], [*(range(0, 24))], ['2017', '2018', '2019']]\n",
    "\n",
    "        x = convert_to_categorical(x, categorical_variables, categories, need_pickup = need_pickup)\n",
    "\n",
    "        \n",
    "        # Make dummy variables with the categorical ones\n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            begin = 1\n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            x = dummie_and_drop(x, name = categorical_variables[i])\n",
    "\n",
    "        y = df['Trips'].to_numpy()\n",
    "\n",
    "        if need_pickup == False:\n",
    "            # If we don't need the pickup, it means this is Neural Network case. Therefore we have to modify Y, in order\n",
    "            # to have \"n_areas\" outputs per input (because there are \"n_areas\" regressions per input)\n",
    "            n_areas = 77\n",
    "            y = np.reshape(y, [-1, n_areas]) # If \n",
    "        \n",
    "        if drop_correlated:\n",
    "            x.drop(columns = ['Trips Last Week (Same Hour)'], inplace = True, axis = 1)\n",
    "            x.drop(columns = ['Trips 2 Weeks Ago (Same Hour)'], inplace = True, axis = 1)\n",
    "\n",
    "        x = x.to_numpy()\n",
    "        \n",
    "        return (x,y)   \n",
    "    \n",
    "# ------------------------------------- MAIN PROGRAM ------------------------\n",
    "\n",
    "    need_pickup = True \n",
    "    drop_correlated = False\n",
    "    \n",
    "    \n",
    "    name_train = 'dataset_train.csv'\n",
    "    name_test = 'dataset_test.csv'\n",
    "    x_train, y_train = load(name_train, need_pickup, drop_correlated)\n",
    "    x_test, y_test = load(name_test, need_pickup, drop_correlated)\n",
    "    \n",
    "    \n",
    "    return (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_taxi():\n",
    "    \n",
    "    def dummie_and_drop(df, name):\n",
    "        # Creates a dummy variable, concatenates it and finally drops the original categorical variable.\n",
    "        # In order not to have redundant variables, one of the dummy variables is dropped too\n",
    "        dummies = pd.get_dummies(df[name]).rename(columns = lambda x: name + '_' + str(x))\n",
    "        dummies = dummies.drop(dummies.columns[-1], axis = 1)\n",
    "        df = pd.concat([df, dummies], axis = 1)\n",
    "        df.drop(columns = [name], inplace=True, axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def convert_to_categorical(df, categorical_variables, categories, need_pickup = True):\n",
    "        \"\"\" \n",
    "        The dataframe's selected variables are converted to categorical, and each variable's categories are also specified.\n",
    "        It is also specified if the \"pickup community area\" has to be converted into categorical or no. If it is not \n",
    "        converted into categorical it is because it's not going to be used in the model.            \n",
    "        \"\"\"\n",
    "        \n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            df.drop(columns = ['pickup_community_area'], inplace = True, axis = 1)\n",
    "            begin = 1\n",
    "        \n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def load(name, need_pickup = False, drop_correlated = False):\n",
    "    \n",
    "        # This parameter has to be set to True if the \"pickup_community_area\" variable is needed in the model\n",
    "        need_pickup = False \n",
    "\n",
    "        # Load needed dataset and choose the useful columns\n",
    "        df = pd.read_csv(name) #'dataset_train.csv')\n",
    "        x = df[['pickup_community_area', 'Day Name', 'Month', 'Hour', 'Fare Last Month', 'Tips Last Month', \n",
    "                'Trips Last Hour', 'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)', 'Year']]\n",
    "\n",
    "        # Convert the categorical variables\n",
    "        categorical_variables = ['pickup_community_area', 'Day Name', 'Month','Hour', 'Year']\n",
    "        categories = [[*(range(1,78))], ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "                      [*(range(1,13))], [*(range(0, 24))], ['2017', '2018', '2019']]\n",
    "\n",
    "        x = convert_to_categorical(x, categorical_variables, categories, need_pickup = need_pickup)\n",
    "\n",
    "        \n",
    "        # Make dummy variables with the categorical ones\n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            begin = 1\n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            x = dummie_and_drop(x, name = categorical_variables[i])\n",
    "\n",
    "        y = df['Trips'].to_numpy()\n",
    "\n",
    "        if need_pickup == False:\n",
    "            # If we don't need the pickup, it means this is Neural Network case. Therefore we have to modify Y, in order\n",
    "            # to have \"n_areas\" outputs per input (because there are \"n_areas\" regressions per input)\n",
    "            n_areas = 77\n",
    "            y = np.reshape(y, [-1, n_areas]) \n",
    "            \n",
    "        if drop_correlated:\n",
    "            x.drop(columns = ['Trips Last Week (Same Hour)'], inplace = True, axis = 1)\n",
    "            x.drop(columns = ['Trips 2 Weeks Ago (Same Hour)'], inplace = True, axis = 1)\n",
    "\n",
    "        x = x.to_numpy()\n",
    "        \n",
    "        return (x,y)\n",
    "\n",
    "    \n",
    "    \n",
    "    need_pickup = True \n",
    "    drop_correlated = True\n",
    "    \n",
    "    name_train = 'dataset_train.csv'\n",
    "    name_test = 'dataset_test.csv'\n",
    "    x_train, y_train = load(name_train, need_pickup, drop_correlated)\n",
    "    x_test, y_test = load(name_test, need_pickup, drop_correlated)\n",
    "    \n",
    "    \n",
    "    return (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['mae'])\n",
    "    plt.plot(history.history['val_mae'])\n",
    "    plt.title('Model mean absolute error')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x, x_test, y, y_test): #n_areas, features, x_train, y_train):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    \n",
    "    # In order to get reproducible results\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(2020)\n",
    "    from numpy.random import seed\n",
    "    seed(1)\n",
    "    \n",
    "    n_areas = y.shape[1]\n",
    "    features = x.shape[1]\n",
    "    \n",
    "    act = {{choice(['relu', 'sigmoid', 'tanh'])}} # Choose the activation function\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Choose the architecture\n",
    "    architecture = {{choice(['arc_0', 'arc_1', 'arc_2', 'arc_3', 'arc_4'])}}\n",
    "    \n",
    "    if architecture == 'arc_0':\n",
    "        model.add(Dense(32, activation = act, input_shape = (features,)))\n",
    "        model.add(Dense(64, activation= act))\n",
    "        model.add(Dense(32, activation= act))\n",
    "    \n",
    "    elif architecture == 'arc_1':\n",
    "        model.add(Dense(64, activation = act, input_shape = (features,)))\n",
    "        model.add(Dense(128, activation= act))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        model.add(Dense(128, activation= act))\n",
    "    \n",
    "    elif architecture == 'arc_2':\n",
    "        model.add(Dense(128, activation = act, input_shape = (features,)))\n",
    "        model.add(Dense(128, activation= act))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        \n",
    "    elif architecture == 'arc_3':\n",
    "        model.add(Dense(128, activation = act, input_shape = (features,)))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(1024, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        model.add(Dense(128, activation= act))\n",
    "        \n",
    "    elif architecture == 'arc_4':\n",
    "        model.add(Dense(256, activation = act, input_shape = (features,)))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(1024, activation= act))\n",
    "        model.add(Dense(1024, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(256, activation= act))\n",
    "\n",
    "    model.add(Dense(n_areas))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer = {{choice(['adam', 'rmsprop' , 'sgd'])}}, loss = 'mse', metrics = ['mae'])\n",
    "    model.summary()\n",
    "    \n",
    "    # checkpoint\n",
    "#     filepath=\"weights-improvement-{epoch:02d}-{val_mae:.2f}.hdf5\"\n",
    "#     checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
    "#     callbacks_list = [checkpoint]\n",
    "    \n",
    "#     model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose = 0) #callbacks=callbacks_list, verbose=0)\n",
    "    \n",
    "    result = model.fit(x = x, y = y, validation_split = 0.15, \n",
    "                        batch_size = {{choice([32, 64, 128])}},\n",
    "                        epochs = 200, verbose = 0)\n",
    "    \n",
    "    validation_mae = np.amin(result.history['val_mae']) \n",
    "    print('Best validation mae of epoch:', validation_mae)\n",
    "    return {'loss': validation_mae, 'status': STATUS_OK, 'model': model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from numpy.random import seed\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import model_from_json\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'act': hp.choice('act', ['relu', 'sigmoid', 'tanh']),\n",
      "        'act_1': hp.choice('act_1', ['ampliate', 'not_ampliate']),\n",
      "        'act_2': hp.choice('act_2', ['ampliate_more', 'not']),\n",
      "        'optimizer': hp.choice('optimizer', ['adam', 'rmsprop' , 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: \n",
      "   3: def dummie_and_drop(df, name):\n",
      "   4:     # Creates a dummy variable, concatenates it and finally drops the original categorical variable\n",
      "   5:     dummies = pd.get_dummies(df[name]).rename(columns = lambda x: name + '_' + str(x))\n",
      "   6:     dummies = dummies.drop(dummies.columns[-1], axis = 1)\n",
      "   7:     df = pd.concat([df, dummies], axis = 1)\n",
      "   8:     df.drop(columns = [name], inplace=True, axis=1)\n",
      "   9: \n",
      "  10:     return df\n",
      "  11: \n",
      "  12: def convert_to_categorical(df, need_pickup = True):\n",
      "  13:     \n",
      "  14:     categorical_variables = ['pickup_community_area', 'daytype', 'sky_level', 'Day Name', 'Month','Hour', ]\n",
      "  15:     categories = [[*(range(1,78))], ['U', 'W', 'A'], ['OVC', 'BKN', 'SCT', 'FEW', 'CLR', 'VV '], \n",
      "  16:                   ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
      "  17:                   [*(range(1,13))], [*(range(0, 24))]]\n",
      "  18:     \n",
      "  19:     if need_pickup:\n",
      "  20:         begin = 0\n",
      "  21:     else:\n",
      "  22:         df.drop(columns = ['pickup_community_area'], inplace = True, axis = 1)\n",
      "  23:         begin = 1\n",
      "  24:     \n",
      "  25:     for i in range(begin, len(categorical_variables)):\n",
      "  26:         df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n",
      "  27:     return df\n",
      "  28: \n",
      "  29: need_pickup = False # set to false if it is not needed (Neural Network case)\n",
      "  30: \n",
      "  31: \n",
      "  32: df = pd.read_csv('dataset_train.csv')\n",
      "  33: x = df[['pickup_community_area' ,'temperature', 'relative_humidity', 'wind_direction', 'wind_speed', 'precipitation_cat', 'sky_level',\n",
      "  34:     'daytype', 'Day Name', 'Month', 'Hour', 'Fare Last Month', 'Tips Last Month', 'Trips Last Hour',\n",
      "  35:     'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)', 'trip_start_timestamp']]\n",
      "  36: \n",
      "  37: \n",
      "  38: x = convert_to_categorical(x, need_pickup = need_pickup)\n",
      "  39: \n",
      "  40: # Take the features needed, and build new ones\n",
      "  41: \n",
      "  42: \n",
      "  43: \n",
      "  44: categorical_variables = ['pickup_community_area', 'sky_level', 'daytype', 'Day Name', 'Month', 'Hour']\n",
      "  45: \n",
      "  46: if need_pickup:\n",
      "  47:     begin = 0\n",
      "  48: else:\n",
      "  49:     begin = 1\n",
      "  50: \n",
      "  51: for i in range(begin, len(categorical_variables)):\n",
      "  52:     x = dummie_and_drop(x, name = categorical_variables[i])\n",
      "  53: print(x.columns)\n",
      "  54: n_areas = 77\n",
      "  55: y = df['Trips'].to_numpy()\n",
      "  56: y = np.reshape(y, [-1, n_areas])\n",
      "  57: x = x.groupby('trip_start_timestamp').mean()\n",
      "  58: x = x.to_numpy()\n",
      "  59: assert(len(y) == len(x))\n",
      "  60: x, x_val, y, y_val = train_test_split(x,y, test_size = 0.15, random_state = 2020)\n",
      "  61: \n",
      "  62: \n",
      "  63: \n",
      "  64: \n",
      "  65: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \n",
      "   4:     # In order to get reproducible results\n",
      "   5:     tf.random.set_seed(2020)\n",
      "   6:     seed(1)\n",
      "   7:     \n",
      "   8:     n_areas = y.shape[1]\n",
      "   9:     features = x.shape[1]\n",
      "  10:     \n",
      "  11:     act = space['act'] # Choose the activation function\n",
      "  12:     \n",
      "  13:     model = Sequential()\n",
      "  14:     model.add(Dense(256, activation = act, input_shape = (features,)))\n",
      "  15:     model.add(Dense(512, activation = act))\n",
      "  16:     model.add(Dense(512, activation = act))\n",
      "  17:     \n",
      "  18:     if space['act_1'] == 'ampliate': # Choose the ampliation of the architecture\n",
      "  19:         model.add(Dense(1024, activation = act))\n",
      "  20:         if space['act_2'] == 'ampliate_more': # Choose further the ampliation of the architecture\n",
      "  21:             model.add(Dense(2048, activation = act))\n",
      "  22:             model.add(Dense(2048, activation = act))\n",
      "  23:         \n",
      "  24:         model.add(Dense(1024, activation = act))\n",
      "  25: \n",
      "  26:     \n",
      "  27:     model.add(Dense(512, activation = act))\n",
      "  28:     model.add(Dense(256, activation = act))\n",
      "  29:     model.add(Dense(n_areas))\n",
      "  30:     \n",
      "  31:     \n",
      "  32:     model.compile(optimizer = space['optimizer'], loss = 'mse', metrics = ['mae'])\n",
      "  33:     model.summary()\n",
      "  34:     \n",
      "  35:     # checkpoint\n",
      "  36: #     filepath=\"weights-improvement-{epoch:02d}-{val_mae:.2f}.hdf5\"\n",
      "  37: #     checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
      "  38: #     callbacks_list = [checkpoint]\n",
      "  39:     \n",
      "  40: #     model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose = 0) #callbacks=callbacks_list, verbose=0)\n",
      "  41:     \n",
      "  42:     result = model.fit(x = x, y = y, validation_split = 0.15, \n",
      "  43:                         batch_size = space['batch_size'],\n",
      "  44:                         epochs = 200, verbose = 0)\n",
      "  45:     \n",
      "  46:     validation_mae = np.amin(result.history['val_mae']) \n",
      "  47:     print('Best validation mae of epoch:', validation_mae)\n",
      "  48:     return {'loss': validation_mae, 'status': STATUS_OK, 'model': model}\n",
      "  49: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs_julen\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\julen\\OneDrive\\Escritorio\\github\\project_CSP_MATH_571\\srDataSets\\temp_model.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['temperature', 'relative_humidity', 'wind_direction', 'wind_speed',\n",
      "       'precipitation_cat', 'Fare Last Month', 'Tips Last Month',\n",
      "       'Trips Last Hour', 'Trips Last Week (Same Hour)',\n",
      "       'Trips 2 Weeks Ago (Same Hour)', 'trip_start_timestamp',\n",
      "       'sky_level_OVC', 'sky_level_BKN', 'sky_level_SCT', 'sky_level_FEW',\n",
      "       'sky_level_CLR', 'daytype_U', 'daytype_W', 'Day Name_Monday',\n",
      "       'Day Name_Tuesday', 'Day Name_Wednesday', 'Day Name_Thursday',\n",
      "       'Day Name_Friday', 'Day Name_Saturday', 'Month_1', 'Month_2', 'Month_3',\n",
      "       'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9',\n",
      "       'Month_10', 'Month_11', 'Hour_0', 'Hour_1', 'Hour_2', 'Hour_3',\n",
      "       'Hour_4', 'Hour_5', 'Hour_6', 'Hour_7', 'Hour_8', 'Hour_9', 'Hour_10',\n",
      "       'Hour_11', 'Hour_12', 'Hour_13', 'Hour_14', 'Hour_15', 'Hour_16',\n",
      "       'Hour_17', 'Hour_18', 'Hour_19', 'Hour_20', 'Hour_21', 'Hour_22'],\n",
      "      dtype='object')\n",
      "Model: \"sequential_1\"                                \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               14848     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 77)                19789     \n",
      "=================================================================\n",
      "Total params: 10,004,045                             \n",
      "Trainable params: 10,004,045                         \n",
      "Non-trainable params: 0                              \n",
      "_________________________________________________________________\n",
      "Best validation mae of epoch:                        \n",
      "2.3488779067993164                                   \n",
      "Model: \"sequential_2\"                                                           \n",
      "_________________________________________________________________               \n",
      "Layer (type)                 Output Shape              Param #                  \n",
      "=================================================================               \n",
      "dense_11 (Dense)             (None, 256)               14848                    \n",
      "_________________________________________________________________               \n",
      "dense_12 (Dense)             (None, 512)               131584                   \n",
      "_________________________________________________________________               \n",
      "dense_13 (Dense)             (None, 512)               262656                   \n",
      "_________________________________________________________________               \n",
      "dense_14 (Dense)             (None, 1024)              525312                   \n",
      "_________________________________________________________________               \n",
      "dense_15 (Dense)             (None, 1024)              1049600                  \n",
      "_________________________________________________________________               \n",
      "dense_16 (Dense)             (None, 512)               524800                   \n",
      "_________________________________________________________________               \n",
      "dense_17 (Dense)             (None, 256)               131328                   \n",
      "_________________________________________________________________               \n",
      "dense_18 (Dense)             (None, 77)                19789                    \n",
      "=================================================================               \n",
      "Total params: 2,659,917                                                         \n",
      "Trainable params: 2,659,917                                                     \n",
      "Non-trainable params: 0                                                         \n",
      "_________________________________________________________________               \n",
      "Best validation mae of epoch:                                                   \n",
      "2.348510980606079                                                               \n",
      "Model: \"sequential_3\"                                                           \n",
      "_________________________________________________________________              \n",
      "Layer (type)                 Output Shape              Param #                 \n",
      "=================================================================              \n",
      "dense_19 (Dense)             (None, 256)               14848                   \n",
      "_________________________________________________________________              \n",
      "dense_20 (Dense)             (None, 512)               131584                  \n",
      "_________________________________________________________________              \n",
      "dense_21 (Dense)             (None, 512)               262656                  \n",
      "_________________________________________________________________              \n",
      "dense_22 (Dense)             (None, 1024)              525312                  \n",
      "_________________________________________________________________              \n",
      "dense_23 (Dense)             (None, 2048)              2099200                 \n",
      "_________________________________________________________________              \n",
      "dense_24 (Dense)             (None, 2048)              4196352                 \n",
      "_________________________________________________________________              \n",
      "dense_25 (Dense)             (None, 1024)              2098176                 \n",
      "_________________________________________________________________              \n",
      "dense_26 (Dense)             (None, 512)               524800                  \n",
      "_________________________________________________________________              \n",
      "dense_27 (Dense)             (None, 256)               131328                  \n",
      "_________________________________________________________________              \n",
      "dense_28 (Dense)             (None, 77)                19789                   \n",
      "=================================================================              \n",
      "Total params: 10,004,045                                                       \n",
      "Trainable params: 10,004,045                                                   \n",
      "Non-trainable params: 0                                                        \n",
      "_________________________________________________________________              \n",
      "Best validation mae of epoch:                                                  \n",
      "2.357203722000122                                                              \n",
      "Model: \"sequential_4\"                                                          \n",
      "_________________________________________________________________              \n",
      "Layer (type)                 Output Shape              Param #                 \n",
      "=================================================================              \n",
      "dense_29 (Dense)             (None, 256)               14848                   \n",
      "_________________________________________________________________              \n",
      "dense_30 (Dense)             (None, 512)               131584                  \n",
      "_________________________________________________________________              \n",
      "dense_31 (Dense)             (None, 512)               262656                  \n",
      "_________________________________________________________________              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_32 (Dense)             (None, 512)               262656                  \n",
      "_________________________________________________________________              \n",
      "dense_33 (Dense)             (None, 256)               131328                  \n",
      "_________________________________________________________________              \n",
      "dense_34 (Dense)             (None, 77)                19789                   \n",
      "=================================================================              \n",
      "Total params: 822,861                                                          \n",
      "Trainable params: 822,861                                                      \n",
      "Non-trainable params: 0                                                        \n",
      "_________________________________________________________________              \n",
      "Best validation mae of epoch:                                                  \n",
      "2.3139119148254395                                                             \n",
      "Model: \"sequential_5\"                                                           \n",
      "_________________________________________________________________               \n",
      "Layer (type)                 Output Shape              Param #                  \n",
      "=================================================================               \n",
      "dense_35 (Dense)             (None, 256)               14848                    \n",
      "_________________________________________________________________               \n",
      "dense_36 (Dense)             (None, 512)               131584                   \n",
      "_________________________________________________________________               \n",
      "dense_37 (Dense)             (None, 512)               262656                   \n",
      "_________________________________________________________________               \n",
      "dense_38 (Dense)             (None, 512)               262656                   \n",
      "_________________________________________________________________               \n",
      "dense_39 (Dense)             (None, 256)               131328                   \n",
      "_________________________________________________________________               \n",
      "dense_40 (Dense)             (None, 77)                19789                    \n",
      "=================================================================               \n",
      "Total params: 822,861                                                           \n",
      "Trainable params: 822,861                                                       \n",
      "Non-trainable params: 0                                                         \n",
      "_________________________________________________________________               \n",
      "Best validation mae of epoch:                                                   \n",
      "2.345154047012329                                                               \n",
      "Model: \"sequential_6\"                                                           \n",
      "_________________________________________________________________               \n",
      "Layer (type)                 Output Shape              Param #                  \n",
      "=================================================================               \n",
      "dense_41 (Dense)             (None, 256)               14848                    \n",
      "_________________________________________________________________               \n",
      "dense_42 (Dense)             (None, 512)               131584                   \n",
      "_________________________________________________________________               \n",
      "dense_43 (Dense)             (None, 512)               262656                   \n",
      "_________________________________________________________________               \n",
      "dense_44 (Dense)             (None, 1024)              525312                   \n",
      "_________________________________________________________________               \n",
      "dense_45 (Dense)             (None, 2048)              2099200                  \n",
      "_________________________________________________________________               \n",
      "dense_46 (Dense)             (None, 2048)              4196352                  \n",
      "_________________________________________________________________               \n",
      "dense_47 (Dense)             (None, 1024)              2098176                  \n",
      "_________________________________________________________________               \n",
      "dense_48 (Dense)             (None, 512)               524800                   \n",
      "_________________________________________________________________               \n",
      "dense_49 (Dense)             (None, 256)               131328                   \n",
      "_________________________________________________________________               \n",
      "dense_50 (Dense)             (None, 77)                19789                    \n",
      "=================================================================               \n",
      "Total params: 10,004,045                                                        \n",
      "Trainable params: 10,004,045                                                    \n",
      "Non-trainable params: 0                                                         \n",
      "_________________________________________________________________               \n",
      "Best validation mae of epoch:                                                   \n",
      "nan                                                                             \n",
      "Model: \"sequential_7\"                                                           \n",
      "_________________________________________________________________               \n",
      "Layer (type)                 Output Shape              Param #                  \n",
      "=================================================================               \n",
      "dense_51 (Dense)             (None, 256)               14848                    \n",
      "_________________________________________________________________               \n",
      "dense_52 (Dense)             (None, 512)               131584                   \n",
      "_________________________________________________________________               \n",
      "dense_53 (Dense)             (None, 512)               262656                   \n",
      "_________________________________________________________________               \n",
      "dense_54 (Dense)             (None, 1024)              525312                   \n",
      "_________________________________________________________________               \n",
      "dense_55 (Dense)             (None, 2048)              2099200                  \n",
      "_________________________________________________________________               \n",
      "dense_56 (Dense)             (None, 2048)              4196352                  \n",
      "_________________________________________________________________               \n",
      "dense_57 (Dense)             (None, 1024)              2098176                  \n",
      "_________________________________________________________________               \n",
      "dense_58 (Dense)             (None, 512)               524800                   \n",
      "_________________________________________________________________               \n",
      "dense_59 (Dense)             (None, 256)               131328                   \n",
      "_________________________________________________________________               \n",
      "dense_60 (Dense)             (None, 77)                19789                    \n",
      "=================================================================               \n",
      "Total params: 10,004,045                                                        \n",
      "Trainable params: 10,004,045                                                    \n",
      "Non-trainable params: 0                                                         \n",
      "_________________________________________________________________               \n",
      "Best validation mae of epoch:                                                   \n",
      "1.150505542755127                                                                 \n",
      "Model: \"sequential_8\"                                                             \n",
      "_________________________________________________________________                \n",
      "Layer (type)                 Output Shape              Param #                   \n",
      "=================================================================                \n",
      "dense_61 (Dense)             (None, 256)               14848                     \n",
      "_________________________________________________________________                \n",
      "dense_62 (Dense)             (None, 512)               131584                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________                \n",
      "dense_63 (Dense)             (None, 512)               262656                    \n",
      "_________________________________________________________________                \n",
      "dense_64 (Dense)             (None, 512)               262656                    \n",
      "_________________________________________________________________                \n",
      "dense_65 (Dense)             (None, 256)               131328                    \n",
      "_________________________________________________________________                \n",
      "dense_66 (Dense)             (None, 77)                19789                     \n",
      "=================================================================                \n",
      "Total params: 822,861                                                            \n",
      "Trainable params: 822,861                                                        \n",
      "Non-trainable params: 0                                                          \n",
      "_________________________________________________________________                \n",
      "Best validation mae of epoch:                                                    \n",
      "2.348464250564575                                                                \n",
      "100%|██████████| 8/8 [1:05:51<00:00, 493.89s/trial, best loss: 1.150505542755127]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs_julen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['temperature', 'relative_humidity', 'wind_direction', 'wind_speed',\n",
      "       'precipitation_cat', 'Fare Last Month', 'Tips Last Month',\n",
      "       'Trips Last Hour', 'Trips Last Week (Same Hour)',\n",
      "       'Trips 2 Weeks Ago (Same Hour)', 'trip_start_timestamp',\n",
      "       'sky_level_OVC', 'sky_level_BKN', 'sky_level_SCT', 'sky_level_FEW',\n",
      "       'sky_level_CLR', 'daytype_U', 'daytype_W', 'Day Name_Monday',\n",
      "       'Day Name_Tuesday', 'Day Name_Wednesday', 'Day Name_Thursday',\n",
      "       'Day Name_Friday', 'Day Name_Saturday', 'Month_1', 'Month_2', 'Month_3',\n",
      "       'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9',\n",
      "       'Month_10', 'Month_11', 'Hour_0', 'Hour_1', 'Hour_2', 'Hour_3',\n",
      "       'Hour_4', 'Hour_5', 'Hour_6', 'Hour_7', 'Hour_8', 'Hour_9', 'Hour_10',\n",
      "       'Hour_11', 'Hour_12', 'Hour_13', 'Hour_14', 'Hour_15', 'Hour_16',\n",
      "       'Hour_17', 'Hour_18', 'Hour_19', 'Hour_20', 'Hour_21', 'Hour_22'],\n",
      "      dtype='object')\n",
      "Evalutation of best performing model:\n",
      "3633/3633 [==============================] - 0s 67us/step\n",
      "[17.23733091341245, 1.2141263484954834]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'act': 0, 'act_1': 0, 'act_2': 0, 'batch_size': 0, 'optimizer': 0}\n"
     ]
    }
   ],
   "source": [
    "exec('from __future__ import absolute_import, division, print_function')\n",
    "import numpy as np\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "best_run, best_model = optim.minimize(model = create_model,\n",
    "                                      data = load_data,\n",
    "                                      algo = tpe.suggest, \n",
    "                                      max_evals = 8,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name = 'Model_Neural_Network')\n",
    "x, x_val, y, y_val = load_data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_val, y_val))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "\n",
    "# plot_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  2,  4,  2,  2, 12,  6, 51,  0,  0,  1,  0,  0,  1,  1,  2,\n",
       "         0,  0,  0,  0,  1,  2,  0,  4,  0,  0,  0, 13,  0,  0,  0, 22,\n",
       "         3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 11,  3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(best_model.predict(x[0:1])).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  0,  3,  2,  1, 14,  5, 60,  0,  0,  0,  0,  0,  3,  0,  3,  0,\n",
       "        0,  1,  0,  0,  1,  0,  6,  1,  0,  0,  7,  0,  0,  0, 26,  3,  0,\n",
       "        2,  0,  0,  1,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  2,  0,  0,\n",
       "        0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,\n",
       "        0,  1,  0,  0,  0,  0,  0,  9,  6], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.31408977508545, 1.3076363801956177]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(x_test[0:1], y_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 66)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.37974119e+00,  2.24573636e+00,  3.78148508e+00,\n",
       "         2.38664103e+00,  2.00838447e+00,  1.27829924e+01,\n",
       "         6.88590622e+00,  5.11086655e+01, -2.03334481e-01,\n",
       "         4.65536833e-01,  6.12488925e-01, -2.29467943e-01,\n",
       "         3.05308819e-01,  1.66380143e+00,  6.24546885e-01,\n",
       "         1.87013221e+00,  1.96223632e-01, -1.15499526e-01,\n",
       "         8.94508213e-02,  1.47701412e-01,  6.10566974e-01,\n",
       "         2.25085664e+00,  1.65941089e-01,  5.27327442e+00,\n",
       "         3.54929894e-01,  8.10648575e-02,  1.00148916e-02,\n",
       "         1.21229258e+01,  2.68596530e-01, -4.55120504e-02,\n",
       "         6.19136810e-01,  2.08747215e+01,  2.68774939e+00,\n",
       "         1.59481615e-01,  1.83791831e-01,  2.04227477e-01,\n",
       "         6.04685321e-02,  1.46532863e-01,  1.84166983e-01,\n",
       "        -3.69561613e-01,  3.91467571e-01, -2.94932425e-02,\n",
       "         8.51429939e-01,  1.13504231e-01,  4.07641351e-01,\n",
       "         1.56543374e-01,  5.24115264e-02,  1.81086332e-01,\n",
       "         7.37116933e-02, -7.44217634e-02,  2.51282096e-01,\n",
       "        -1.17945470e-01,  3.22190464e-01,  6.93704188e-03,\n",
       "        -1.30907834e-01,  1.18052554e+00,  3.09850350e-02,\n",
       "        -1.17898494e-01,  5.18383831e-02,  1.25881732e-02,\n",
       "         8.15398023e-02, -2.13499188e-01,  1.83379352e-02,\n",
       "        -3.67207751e-02,  1.25478879e-01, -5.93235046e-02,\n",
       "         1.60241067e-01,  7.44529068e-04,  2.74252564e-01,\n",
       "         4.25758958e-01,  4.84544337e-02, -4.99004647e-02,\n",
       "         1.26984715e-02,  6.20458126e-02,  4.11137715e-02,\n",
       "         1.01839495e+01,  3.46760702e+00]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(x_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = best_model.to_json()\n",
    "with open(\"model_neural_network.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "best_model.save_weights(\"model_neural_network.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
