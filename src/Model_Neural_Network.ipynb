{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to get reproducible results\n",
    "\n",
    "# Seed value (can actually be different for each attribution step)\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    def dummie_and_drop(df, name):\n",
    "        # Creates a dummy variable, concatenates it and finally drops the original categorical variable.\n",
    "        # In order not to have redundant variables, one of the dummy variables is dropped too\n",
    "        dummies = pd.get_dummies(df[name]).rename(columns = lambda x: name + '_' + str(x))\n",
    "        dummies = dummies.drop(dummies.columns[-1], axis = 1)\n",
    "        df = pd.concat([df, dummies], axis = 1)\n",
    "        df.drop(columns = [name], inplace=True, axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def convert_to_categorical(df, categorical_variables, categories, need_pickup = True):\n",
    "        \"\"\" \n",
    "        The dataframe's selected variables are converted to categorical, and each variable's categories are also specified.\n",
    "        It is also specified if the \"pickup community area\" has to be converted into categorical or no. If it is not \n",
    "        converted into categorical it is because it's not going to be used in the model.            \n",
    "        \"\"\"\n",
    "        \n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            df.drop(columns = ['pickup_community_area'], inplace = True, axis = 1)\n",
    "            begin = 1\n",
    "        \n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def load(name, need_pickup = False, drop_correlated = False):\n",
    "    \n",
    "        # This parameter has to be set to True if the \"pickup_community_area\" variable is needed in the model\n",
    "        \n",
    "\n",
    "        # Load needed dataset and choose the useful columns\n",
    "        df = pd.read_csv(name) #'dataset_train.csv')\n",
    "        x = df[['pickup_community_area' ,'temperature', 'relative_humidity', 'wind_direction', 'wind_speed', 'precipitation_cat', \n",
    "                'sky_level', 'daytype', 'Day Name', 'Month', 'Hour', 'Fare Last Month', 'Trips Last Hour',\n",
    "                'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)', 'Quarter', 'Year', 'trip_start_timestamp']]\n",
    "\n",
    "        # Convert the categorical variables\n",
    "        categorical_variables = ['pickup_community_area', 'daytype', 'sky_level', 'Day Name', 'Month','Hour', 'Year']\n",
    "        categories = [[*(range(1,78))], ['U', 'W', 'A'], ['OVC', 'BKN', 'SCT', 'FEW', 'CLR', 'VV '], \n",
    "                      ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "                      [*(range(1,13))], [*(range(0, 24))], ['2017', '2018', '2019']]\n",
    "\n",
    "        x = convert_to_categorical(x, categorical_variables, categories, need_pickup = need_pickup)\n",
    "\n",
    "        \n",
    "        # Make dummy variables with the categorical ones\n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            begin = 1\n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            x = dummie_and_drop(x, name = categorical_variables[i])\n",
    "\n",
    "        y = df['Trips'].to_numpy()\n",
    "\n",
    "        if need_pickup == False:\n",
    "            # If we don't need the pickup, it means this is Neural Network case. Therefore we have to modify Y, in order\n",
    "            # to have \"n_areas\" outputs per input (because there are \"n_areas\" regressions per input)\n",
    "            x = x.groupby(by = 'trip_start_timestamp').mean()\n",
    "            n_areas = 77\n",
    "            y = np.reshape(y, [-1, n_areas]) # If \n",
    "        else:\n",
    "            x.drop(columns = ['trip_start_timestamp'], inplace = True, axis = 1)\n",
    "        \n",
    "        if drop_correlated:\n",
    "            x.drop(columns = ['Trips Last Week (Same Hour)'], inplace = True, axis = 1)\n",
    "            x.drop(columns = ['Trips 2 Weeks Ago (Same Hour)'], inplace = True, axis = 1)\n",
    "\n",
    "        x = x.to_numpy()\n",
    "        \n",
    "        return (x,y)   \n",
    "    \n",
    "\n",
    "    need_pickup = False \n",
    "    drop_correlated = False\n",
    "    \n",
    "    \n",
    "    name_train = 'dataset_train.csv'\n",
    "    name_test = 'dataset_test.csv'\n",
    "    x, y = load(name_train, need_pickup, drop_correlated)\n",
    "    x_test, y_test = load(name_test, need_pickup, drop_correlated)\n",
    "    \n",
    "    \n",
    "    return (x, x_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs_julen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "x, x_test, y, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1864632, 59)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24216, 77)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_taxi():\n",
    "    \n",
    "    def dummie_and_drop(df, name):\n",
    "        # Creates a dummy variable, concatenates it and finally drops the original categorical variable.\n",
    "        # In order not to have redundant variables, one of the dummy variables is dropped too\n",
    "        dummies = pd.get_dummies(df[name]).rename(columns = lambda x: name + '_' + str(x))\n",
    "        dummies = dummies.drop(dummies.columns[-1], axis = 1)\n",
    "        df = pd.concat([df, dummies], axis = 1)\n",
    "        df.drop(columns = [name], inplace=True, axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def convert_to_categorical(df, categorical_variables, categories, need_pickup = True):\n",
    "        \"\"\" \n",
    "        The dataframe's selected variables are converted to categorical, and each variable's categories are also specified.\n",
    "        It is also specified if the \"pickup community area\" has to be converted into categorical or no. If it is not \n",
    "        converted into categorical it is because it's not going to be used in the model.            \n",
    "        \"\"\"\n",
    "        \n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            df.drop(columns = ['pickup_community_area'], inplace = True, axis = 1)\n",
    "            begin = 1\n",
    "        \n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def load(name, need_pickup = False, drop_correlated = False):\n",
    "    \n",
    "        # This parameter has to be set to True if the \"pickup_community_area\" variable is needed in the model\n",
    "        need_pickup = False \n",
    "\n",
    "        # Load needed dataset and choose the useful columns\n",
    "        df = pd.read_csv(name) #'dataset_train.csv')\n",
    "        x = df[['pickup_community_area', 'Day Name', 'Month', 'Hour', 'Fare Last Month', 'Tips Last Month', \n",
    "                'Trips Last Hour', 'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)', 'Year']]\n",
    "\n",
    "        # Convert the categorical variables\n",
    "        categorical_variables = ['pickup_community_area', 'Day Name', 'Month','Hour', 'Year']\n",
    "        categories = [[*(range(1,78))], ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "                      [*(range(1,13))], [*(range(0, 24))], ['2017', '2018', '2019']]\n",
    "\n",
    "        x = convert_to_categorical(x, categorical_variables, categories, need_pickup = need_pickup)\n",
    "\n",
    "        \n",
    "        # Make dummy variables with the categorical ones\n",
    "        if need_pickup:\n",
    "            begin = 0\n",
    "        else:\n",
    "            begin = 1\n",
    "        for i in range(begin, len(categorical_variables)):\n",
    "            x = dummie_and_drop(x, name = categorical_variables[i])\n",
    "\n",
    "        y = df['Trips'].to_numpy()\n",
    "\n",
    "        if need_pickup == False:\n",
    "            # If we don't need the pickup, it means this is Neural Network case. Therefore we have to modify Y, in order\n",
    "            # to have \"n_areas\" outputs per input (because there are \"n_areas\" regressions per input)\n",
    "            n_areas = 77\n",
    "            y = np.reshape(y, [-1, n_areas]) \n",
    "            \n",
    "        if drop_correlated:\n",
    "            x.drop(columns = ['Trips Last Week (Same Hour)'], inplace = True, axis = 1)\n",
    "            x.drop(columns = ['Trips 2 Weeks Ago (Same Hour)'], inplace = True, axis = 1)\n",
    "\n",
    "        x = x.to_numpy()\n",
    "        \n",
    "        return (x,y)\n",
    "\n",
    "    need_pickup = True \n",
    "    drop_correlated = True\n",
    "    \n",
    "    name_train = 'dataset_train.csv'\n",
    "    name_test = 'dataset_test.csv'\n",
    "    x_train, y_train = load(name_train, need_pickup, drop_correlated)\n",
    "    x_test, y_test = load(name_test, need_pickup, drop_correlated)\n",
    "    \n",
    "    \n",
    "    return (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['mae'])\n",
    "    plt.plot(history.history['val_mae'])\n",
    "    plt.title('Model mean absolute error')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x, x_test, y, y_test): #n_areas, features, x_train, y_train):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    \n",
    "    # In order to get reproducible results\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(2020)\n",
    "    from numpy.random import seed\n",
    "    seed(1)\n",
    "    \n",
    "    n_areas = y.shape[1]\n",
    "    features = x.shape[1]\n",
    "    \n",
    "    act = {{choice(['relu', 'sigmoid', 'tanh'])}} # Choose the activation function\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Choose the architecture\n",
    "    architecture = {{choice(['arc_0', 'arc_1', 'arc_2', 'arc_3', 'arc_4'])}}\n",
    "    \n",
    "    if architecture == 'arc_0':\n",
    "        model.add(Dense(32, activation = act, input_shape = (features,)))\n",
    "        model.add(Dense(64, activation= act))\n",
    "        model.add(Dense(32, activation= act))\n",
    "    \n",
    "    elif architecture == 'arc_1':\n",
    "        model.add(Dense(64, activation = act, input_shape = (features,)))\n",
    "        model.add(Dense(128, activation= act))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        model.add(Dense(128, activation= act))\n",
    "    \n",
    "    elif architecture == 'arc_2':\n",
    "        model.add(Dense(128, activation = act, input_shape = (features,)))\n",
    "        model.add(Dense(128, activation= act))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        \n",
    "    elif architecture == 'arc_3':\n",
    "        model.add(Dense(128, activation = act, input_shape = (features,)))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(1024, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        model.add(Dense(128, activation= act))\n",
    "        \n",
    "    elif architecture == 'arc_4':\n",
    "        model.add(Dense(256, activation = act, input_shape = (features,)))\n",
    "        model.add(Dense(256, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(1024, activation= act))\n",
    "        model.add(Dense(1024, activation= act))\n",
    "        model.add(Dense(512, activation= act))\n",
    "        model.add(Dense(256, activation= act))\n",
    "\n",
    "    model.add(Dense(n_areas))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer = {{choice(['adam', 'rmsprop' , 'sgd'])}}, loss = 'mse', metrics = ['mae'])\n",
    "    model.summary()\n",
    "    \n",
    "    # checkpoint\n",
    "#     filepath=\"weights-improvement-{epoch:02d}-{val_mae:.2f}.hdf5\"\n",
    "#     checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
    "#     callbacks_list = [checkpoint]\n",
    "    \n",
    "#     model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose = 0) #callbacks=callbacks_list, verbose=0)\n",
    "    \n",
    "    result = model.fit(x = x, y = y, validation_split = 0.15, \n",
    "                        batch_size = {{choice([32, 64, 128])}},\n",
    "                        epochs = 200, verbose = 0)\n",
    "    \n",
    "    validation_mae = np.amin(result.history['val_mae']) \n",
    "    print('Best validation mae of epoch:', validation_mae)\n",
    "    return {'loss': validation_mae, 'status': STATUS_OK, 'model': model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from numpy.random import seed\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import model_from_json\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'act': hp.choice('act', ['relu', 'sigmoid', 'tanh']),\n",
      "        'architecture': hp.choice('architecture', ['arc_0', 'arc_1', 'arc_2', 'arc_3', 'arc_4']),\n",
      "        'optimizer': hp.choice('optimizer', ['adam', 'rmsprop' , 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: \n",
      "   3: def dummie_and_drop(df, name):\n",
      "   4:     # Creates a dummy variable, concatenates it and finally drops the original categorical variable.\n",
      "   5:     # In order not to have redundant variables, one of the dummy variables is dropped too\n",
      "   6:     dummies = pd.get_dummies(df[name]).rename(columns = lambda x: name + '_' + str(x))\n",
      "   7:     dummies = dummies.drop(dummies.columns[-1], axis = 1)\n",
      "   8:     df = pd.concat([df, dummies], axis = 1)\n",
      "   9:     df.drop(columns = [name], inplace=True, axis=1)\n",
      "  10: \n",
      "  11:     return df\n",
      "  12: \n",
      "  13: def convert_to_categorical(df, categorical_variables, categories, need_pickup = True):\n",
      "  14:     \"\"\" \n",
      "  15:     The dataframe's selected variables are converted to categorical, and each variable's categories are also specified.\n",
      "  16:     It is also specified if the \"pickup community area\" has to be converted into categorical or no. If it is not \n",
      "  17:     converted into categorical it is because it's not going to be used in the model.            \n",
      "  18:     \"\"\"\n",
      "  19:     \n",
      "  20:     if need_pickup:\n",
      "  21:         begin = 0\n",
      "  22:     else:\n",
      "  23:         df.drop(columns = ['pickup_community_area'], inplace = True, axis = 1)\n",
      "  24:         begin = 1\n",
      "  25:     \n",
      "  26:     for i in range(begin, len(categorical_variables)):\n",
      "  27:         df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n",
      "  28:     return df\n",
      "  29: \n",
      "  30: \n",
      "  31: def load(name, need_pickup = False, drop_correlated = False):\n",
      "  32: \n",
      "  33:     # This parameter has to be set to True if the \"pickup_community_area\" variable is needed in the model\n",
      "  34:     \n",
      "  35: \n",
      "  36:     # Load needed dataset and choose the useful columns\n",
      "  37:     df = pd.read_csv(name) #'dataset_train.csv')\n",
      "  38:     x = df[['pickup_community_area' ,'temperature', 'relative_humidity', 'wind_direction', 'wind_speed', 'precipitation_cat', \n",
      "  39:             'sky_level', 'daytype', 'Day Name', 'Month', 'Hour', 'Fare Last Month', 'Trips Last Hour',\n",
      "  40:             'Trips Last Week (Same Hour)', 'Trips 2 Weeks Ago (Same Hour)', 'Quarter', 'Year', 'trip_start_timestamp']]\n",
      "  41: \n",
      "  42:     # Convert the categorical variables\n",
      "  43:     categorical_variables = ['pickup_community_area', 'daytype', 'sky_level', 'Day Name', 'Month','Hour', 'Year']\n",
      "  44:     categories = [[*(range(1,78))], ['U', 'W', 'A'], ['OVC', 'BKN', 'SCT', 'FEW', 'CLR', 'VV '], \n",
      "  45:                   ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
      "  46:                   [*(range(1,13))], [*(range(0, 24))], ['2017', '2018', '2019']]\n",
      "  47: \n",
      "  48:     x = convert_to_categorical(x, categorical_variables, categories, need_pickup = need_pickup)\n",
      "  49: \n",
      "  50:     \n",
      "  51:     # Make dummy variables with the categorical ones\n",
      "  52:     if need_pickup:\n",
      "  53:         begin = 0\n",
      "  54:     else:\n",
      "  55:         begin = 1\n",
      "  56:     for i in range(begin, len(categorical_variables)):\n",
      "  57:         x = dummie_and_drop(x, name = categorical_variables[i])\n",
      "  58: \n",
      "  59:     y = df['Trips'].to_numpy()\n",
      "  60: \n",
      "  61:     if need_pickup == False:\n",
      "  62:         # If we don't need the pickup, it means this is Neural Network case. Therefore we have to modify Y, in order\n",
      "  63:         # to have \"n_areas\" outputs per input (because there are \"n_areas\" regressions per input)\n",
      "  64:         x = x.groupby(by = 'trip_start_timestamp').mean()\n",
      "  65:         n_areas = 77\n",
      "  66:         y = np.reshape(y, [-1, n_areas]) # If \n",
      "  67:     else:\n",
      "  68:         x.drop(columns = ['trip_start_timestamp'], inplace = True, axis = 1)\n",
      "  69:     \n",
      "  70:     if drop_correlated:\n",
      "  71:         x.drop(columns = ['Trips Last Week (Same Hour)'], inplace = True, axis = 1)\n",
      "  72:         x.drop(columns = ['Trips 2 Weeks Ago (Same Hour)'], inplace = True, axis = 1)\n",
      "  73: \n",
      "  74:     x = x.to_numpy()\n",
      "  75:     \n",
      "  76:     return (x,y)   \n",
      "  77: \n",
      "  78: \n",
      "  79: need_pickup = False \n",
      "  80: drop_correlated = False\n",
      "  81: \n",
      "  82: \n",
      "  83: name_train = 'dataset_train.csv'\n",
      "  84: name_test = 'dataset_test.csv'\n",
      "  85: x, y = load(name_train, need_pickup, drop_correlated)\n",
      "  86: x_test, y_test = load(name_test, need_pickup, drop_correlated)\n",
      "  87: \n",
      "  88: \n",
      "  89: \n",
      "  90: \n",
      "  91: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \n",
      "   4:     # In order to get reproducible results\n",
      "   5:     tf.random.set_seed(2020)\n",
      "   6:     seed(1)\n",
      "   7:     \n",
      "   8:     n_areas = y.shape[1]\n",
      "   9:     features = x.shape[1]\n",
      "  10:     \n",
      "  11:     act = space['act'] # Choose the activation function\n",
      "  12:     \n",
      "  13:     model = Sequential()\n",
      "  14:     # Choose the architecture\n",
      "  15:     architecture = space['architecture']\n",
      "  16:     \n",
      "  17:     if architecture == 'arc_0':\n",
      "  18:         model.add(Dense(32, activation = act, input_shape = (features,)))\n",
      "  19:         model.add(Dense(64, activation= act))\n",
      "  20:         model.add(Dense(32, activation= act))\n",
      "  21:     \n",
      "  22:     elif architecture == 'arc_1':\n",
      "  23:         model.add(Dense(64, activation = act, input_shape = (features,)))\n",
      "  24:         model.add(Dense(128, activation= act))\n",
      "  25:         model.add(Dense(256, activation= act))\n",
      "  26:         model.add(Dense(128, activation= act))\n",
      "  27:     \n",
      "  28:     elif architecture == 'arc_2':\n",
      "  29:         model.add(Dense(128, activation = act, input_shape = (features,)))\n",
      "  30:         model.add(Dense(128, activation= act))\n",
      "  31:         model.add(Dense(256, activation= act))\n",
      "  32:         model.add(Dense(512, activation= act))\n",
      "  33:         model.add(Dense(256, activation= act))\n",
      "  34:         \n",
      "  35:     elif architecture == 'arc_3':\n",
      "  36:         model.add(Dense(128, activation = act, input_shape = (features,)))\n",
      "  37:         model.add(Dense(256, activation= act))\n",
      "  38:         model.add(Dense(512, activation= act))\n",
      "  39:         model.add(Dense(1024, activation= act))\n",
      "  40:         model.add(Dense(512, activation= act))\n",
      "  41:         model.add(Dense(256, activation= act))\n",
      "  42:         model.add(Dense(128, activation= act))\n",
      "  43:         \n",
      "  44:     elif architecture == 'arc_4':\n",
      "  45:         model.add(Dense(256, activation = act, input_shape = (features,)))\n",
      "  46:         model.add(Dense(256, activation= act))\n",
      "  47:         model.add(Dense(512, activation= act))\n",
      "  48:         model.add(Dense(512, activation= act))\n",
      "  49:         model.add(Dense(1024, activation= act))\n",
      "  50:         model.add(Dense(1024, activation= act))\n",
      "  51:         model.add(Dense(512, activation= act))\n",
      "  52:         model.add(Dense(256, activation= act))\n",
      "  53: \n",
      "  54:     model.add(Dense(n_areas))\n",
      "  55:     \n",
      "  56:     \n",
      "  57:     model.compile(optimizer = space['optimizer'], loss = 'mse', metrics = ['mae'])\n",
      "  58:     model.summary()\n",
      "  59:     \n",
      "  60:     # checkpoint\n",
      "  61: #     filepath=\"weights-improvement-{epoch:02d}-{val_mae:.2f}.hdf5\"\n",
      "  62: #     checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
      "  63: #     callbacks_list = [checkpoint]\n",
      "  64:     \n",
      "  65: #     model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose = 0) #callbacks=callbacks_list, verbose=0)\n",
      "  66:     \n",
      "  67:     result = model.fit(x = x, y = y, validation_split = 0.15, \n",
      "  68:                         batch_size = space['batch_size'],\n",
      "  69:                         epochs = 200, verbose = 0)\n",
      "  70:     \n",
      "  71:     validation_mae = np.amin(result.history['val_mae']) \n",
      "  72:     print('Best validation mae of epoch:', validation_mae)\n",
      "  73:     return {'loss': validation_mae, 'status': STATUS_OK, 'model': model}\n",
      "  74: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs_julen\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\julen\\OneDrive\\Escritorio\\github\\project_CSP_MATH_571\\srDataSets\\temp_model.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[categorical_variables[i]] = df[categorical_variables[i]].astype('category').cat.set_categories(categories[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"                                \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 32)                1920      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 77)                2541      \n",
      "=================================================================\n",
      "Total params: 8,653                                  \n",
      "Trainable params: 8,653                              \n",
      "Non-trainable params: 0                              \n",
      "_________________________________________________________________\n",
      "Best validation mae of epoch:                        \n",
      "1.9999483823776245                                   \n",
      "Model: \"sequential_3\"                                                           \n",
      "_________________________________________________________________               \n",
      "Layer (type)                 Output Shape              Param #                  \n",
      "=================================================================               \n",
      "dense_9 (Dense)              (None, 64)                3840                     \n",
      "_________________________________________________________________               \n",
      "dense_10 (Dense)             (None, 128)               8320                     \n",
      "_________________________________________________________________               \n",
      "dense_11 (Dense)             (None, 256)               33024                    \n",
      "_________________________________________________________________               \n",
      "dense_12 (Dense)             (None, 128)               32896                    \n",
      "_________________________________________________________________               \n",
      "dense_13 (Dense)             (None, 77)                9933                     \n",
      "=================================================================               \n",
      "Total params: 88,013                                                            \n",
      "Trainable params: 88,013                                                        \n",
      "Non-trainable params: 0                                                         \n",
      "_________________________________________________________________               \n",
      "Best validation mae of epoch:                                                   \n",
      "1.1543670892715454                                                              \n",
      "Model: \"sequential_4\"                                                           \n",
      "_________________________________________________________________               \n",
      "Layer (type)                 Output Shape              Param #                  \n",
      "=================================================================               \n",
      "dense_14 (Dense)             (None, 256)               15360                    \n",
      "_________________________________________________________________               \n",
      "dense_15 (Dense)             (None, 256)               65792                    \n",
      "_________________________________________________________________               \n",
      "dense_16 (Dense)             (None, 512)               131584                   \n",
      "_________________________________________________________________               \n",
      "dense_17 (Dense)             (None, 512)               262656                   \n",
      "_________________________________________________________________               \n",
      "dense_18 (Dense)             (None, 1024)              525312                   \n",
      "_________________________________________________________________               \n",
      "dense_19 (Dense)             (None, 1024)              1049600                  \n",
      "_________________________________________________________________               \n",
      "dense_20 (Dense)             (None, 512)               524800                   \n",
      "_________________________________________________________________               \n",
      "dense_21 (Dense)             (None, 256)               131328                   \n",
      "_________________________________________________________________               \n",
      "dense_22 (Dense)             (None, 77)                19789                    \n",
      "=================================================================               \n",
      "Total params: 2,726,221                                                         \n",
      "Trainable params: 2,726,221                                                     \n",
      "Non-trainable params: 0                                                         \n",
      "_________________________________________________________________               \n",
      "Best validation mae of epoch:                                                   \n",
      "1.9846088886260986                                                              \n",
      "Model: \"sequential_5\"                                                           \n",
      "_________________________________________________________________               \n",
      "Layer (type)                 Output Shape              Param #                  \n",
      "=================================================================               \n",
      "dense_23 (Dense)             (None, 64)                3840                     \n",
      "_________________________________________________________________               \n",
      "dense_24 (Dense)             (None, 128)               8320                     \n",
      "_________________________________________________________________               \n",
      "dense_25 (Dense)             (None, 256)               33024                    \n",
      "_________________________________________________________________               \n",
      "dense_26 (Dense)             (None, 128)               32896                    \n",
      "_________________________________________________________________               \n",
      "dense_27 (Dense)             (None, 77)                9933                     \n",
      "=================================================================               \n",
      "Total params: 88,013                                                            \n",
      "Trainable params: 88,013                                                        \n",
      "Non-trainable params: 0                                                         \n",
      "_________________________________________________________________               \n",
      "Best validation mae of epoch:                                                   \n",
      "1.9476807117462158                                                              \n",
      "Model: \"sequential_6\"                                                           \n",
      "_________________________________________________________________               \n",
      "Layer (type)                 Output Shape              Param #                  \n",
      "=================================================================               \n",
      "dense_28 (Dense)             (None, 128)               7680                     \n",
      "_________________________________________________________________               \n",
      "dense_29 (Dense)             (None, 256)               33024                    \n",
      "_________________________________________________________________               \n",
      "dense_30 (Dense)             (None, 512)               131584                   \n",
      "_________________________________________________________________               \n",
      "dense_31 (Dense)             (None, 1024)              525312                   \n",
      "_________________________________________________________________               \n",
      "dense_32 (Dense)             (None, 512)               524800                   \n",
      "_________________________________________________________________               \n",
      "dense_33 (Dense)             (None, 256)               131328                   \n",
      "_________________________________________________________________               \n",
      "dense_34 (Dense)             (None, 128)               32896                    \n",
      "_________________________________________________________________               \n",
      "dense_35 (Dense)             (None, 77)                9933                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================               \n",
      "Total params: 1,396,557                                                         \n",
      "Trainable params: 1,396,557                                                     \n",
      "Non-trainable params: 0                                                         \n",
      "_________________________________________________________________               \n",
      "Best validation mae of epoch:                                                   \n",
      "1.9460952281951904                                                              \n",
      "Model: \"sequential_7\"                                                           \n",
      "_________________________________________________________________               \n",
      "Layer (type)                 Output Shape              Param #                  \n",
      "=================================================================               \n",
      "dense_36 (Dense)             (None, 128)               7680                     \n",
      "_________________________________________________________________               \n",
      "dense_37 (Dense)             (None, 256)               33024                    \n",
      "_________________________________________________________________               \n",
      "dense_38 (Dense)             (None, 512)               131584                   \n",
      "_________________________________________________________________               \n",
      "dense_39 (Dense)             (None, 1024)              525312                   \n",
      "_________________________________________________________________               \n",
      "dense_40 (Dense)             (None, 512)               524800                   \n",
      "_________________________________________________________________               \n",
      "dense_41 (Dense)             (None, 256)               131328                   \n",
      "_________________________________________________________________               \n",
      "dense_42 (Dense)             (None, 128)               32896                    \n",
      "_________________________________________________________________               \n",
      "dense_43 (Dense)             (None, 77)                9933                     \n",
      "=================================================================               \n",
      "Total params: 1,396,557                                                         \n",
      "Trainable params: 1,396,557                                                     \n",
      "Non-trainable params: 0                                                         \n",
      "_________________________________________________________________               \n",
      "Best validation mae of epoch:                                                   \n",
      "nan                                                                             \n",
      "Model: \"sequential_8\"                                                           \n",
      "_________________________________________________________________               \n",
      "Layer (type)                 Output Shape              Param #                  \n",
      "=================================================================               \n",
      "dense_44 (Dense)             (None, 128)               7680                     \n",
      "_________________________________________________________________               \n",
      "dense_45 (Dense)             (None, 128)               16512                    \n",
      "_________________________________________________________________               \n",
      "dense_46 (Dense)             (None, 256)               33024                    \n",
      "_________________________________________________________________               \n",
      "dense_47 (Dense)             (None, 512)               131584                   \n",
      "_________________________________________________________________               \n",
      "dense_48 (Dense)             (None, 256)               131328                   \n",
      "_________________________________________________________________               \n",
      "dense_49 (Dense)             (None, 77)                19789                    \n",
      "=================================================================               \n",
      "Total params: 339,917                                                           \n",
      "Trainable params: 339,917                                                       \n",
      "Non-trainable params: 0                                                         \n",
      "_________________________________________________________________               \n",
      "Best validation mae of epoch:                                                   \n",
      "1.0851150751113892                                                              \n",
      "Model: \"sequential_9\"                                                           \n",
      "_________________________________________________________________               \n",
      "Layer (type)                 Output Shape              Param #                  \n",
      "=================================================================               \n",
      "dense_50 (Dense)             (None, 128)               7680                     \n",
      "_________________________________________________________________               \n",
      "dense_51 (Dense)             (None, 256)               33024                    \n",
      "_________________________________________________________________               \n",
      "dense_52 (Dense)             (None, 512)               131584                   \n",
      "_________________________________________________________________               \n",
      "dense_53 (Dense)             (None, 1024)              525312                   \n",
      "_________________________________________________________________               \n",
      "dense_54 (Dense)             (None, 512)               524800                   \n",
      "_________________________________________________________________               \n",
      "dense_55 (Dense)             (None, 256)               131328                   \n",
      "_________________________________________________________________               \n",
      "dense_56 (Dense)             (None, 128)               32896                    \n",
      "_________________________________________________________________               \n",
      "dense_57 (Dense)             (None, 77)                9933                     \n",
      "=================================================================               \n",
      "Total params: 1,396,557                                                         \n",
      "Trainable params: 1,396,557                                                     \n",
      "Non-trainable params: 0                                                         \n",
      "_________________________________________________________________               \n",
      "Best validation mae of epoch:                                                   \n",
      "2.0768980979919434                                                              \n",
      "100%|██████████| 8/8 [30:32<00:00, 229.12s/trial, best loss: 1.0851150751113892]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs_julen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "720/720 [==============================] - 0s 108us/step\n",
      "[16.298441229926215, 1.2575715780258179]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'act': 0, 'architecture': 2, 'batch_size': 0, 'optimizer': 0}\n"
     ]
    }
   ],
   "source": [
    "exec('from __future__ import absolute_import, division, print_function')\n",
    "import numpy as np\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "best_run, best_model = optim.minimize(model = create_model,\n",
    "                                      data = load_data,\n",
    "                                      algo = tpe.suggest, \n",
    "                                      max_evals = 8,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name = 'Model_Neural_Network')\n",
    "x, x_test, y, y_test = load_data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_test, y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "\n",
    "# plot_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  2,  3,  2,  1,  9,  5, 34,  0,  0,  1,  0,  0,  1,  1,  2,\n",
       "         0,  0,  0,  0,  1,  2,  0,  3,  0,  0,  0,  8,  0,  0,  0, 16,\n",
       "         1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  6,  3]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(best_model.predict(x[0:1])).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  0,  4,  3,  2, 33, 11, 58,  0,  0,  1,  0,  0,  4,  0,  0,  0,\n",
       "        0,  0,  0,  2, 11,  0,  7,  3,  0,  0,  9,  0,  0,  1,  5,  1,  0,\n",
       "        0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  7,  4], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.302816390991211, 0.8905684351921082]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(x_test[0:1], y_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 66)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.37974119e+00,  2.24573636e+00,  3.78148508e+00,\n",
       "         2.38664103e+00,  2.00838447e+00,  1.27829924e+01,\n",
       "         6.88590622e+00,  5.11086655e+01, -2.03334481e-01,\n",
       "         4.65536833e-01,  6.12488925e-01, -2.29467943e-01,\n",
       "         3.05308819e-01,  1.66380143e+00,  6.24546885e-01,\n",
       "         1.87013221e+00,  1.96223632e-01, -1.15499526e-01,\n",
       "         8.94508213e-02,  1.47701412e-01,  6.10566974e-01,\n",
       "         2.25085664e+00,  1.65941089e-01,  5.27327442e+00,\n",
       "         3.54929894e-01,  8.10648575e-02,  1.00148916e-02,\n",
       "         1.21229258e+01,  2.68596530e-01, -4.55120504e-02,\n",
       "         6.19136810e-01,  2.08747215e+01,  2.68774939e+00,\n",
       "         1.59481615e-01,  1.83791831e-01,  2.04227477e-01,\n",
       "         6.04685321e-02,  1.46532863e-01,  1.84166983e-01,\n",
       "        -3.69561613e-01,  3.91467571e-01, -2.94932425e-02,\n",
       "         8.51429939e-01,  1.13504231e-01,  4.07641351e-01,\n",
       "         1.56543374e-01,  5.24115264e-02,  1.81086332e-01,\n",
       "         7.37116933e-02, -7.44217634e-02,  2.51282096e-01,\n",
       "        -1.17945470e-01,  3.22190464e-01,  6.93704188e-03,\n",
       "        -1.30907834e-01,  1.18052554e+00,  3.09850350e-02,\n",
       "        -1.17898494e-01,  5.18383831e-02,  1.25881732e-02,\n",
       "         8.15398023e-02, -2.13499188e-01,  1.83379352e-02,\n",
       "        -3.67207751e-02,  1.25478879e-01, -5.93235046e-02,\n",
       "         1.60241067e-01,  7.44529068e-04,  2.74252564e-01,\n",
       "         4.25758958e-01,  4.84544337e-02, -4.99004647e-02,\n",
       "         1.26984715e-02,  6.20458126e-02,  4.11137715e-02,\n",
       "         1.01839495e+01,  3.46760702e+00]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(x_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = best_model.to_json()\n",
    "with open(\"model_neural_network.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "best_model.save_weights(\"model_neural_network.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
